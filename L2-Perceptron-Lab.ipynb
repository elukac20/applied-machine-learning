{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "qlbLb1KVp1LF",
    "outputId": "7ad02d36-7262-4c5a-dd3e-94ce51ff3a43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://51fca8f245f5bd28a1.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://51fca8f245f5bd28a1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/hw_mps/lib/python3.10/site-packages/gradio/queueing.py\", line 766, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/opt/anaconda3/envs/hw_mps/lib/python3.10/site-packages/gradio/route_utils.py\", line 355, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/opt/anaconda3/envs/hw_mps/lib/python3.10/site-packages/gradio/blocks.py\", line 2152, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/opt/anaconda3/envs/hw_mps/lib/python3.10/site-packages/gradio/blocks.py\", line 1629, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/opt/anaconda3/envs/hw_mps/lib/python3.10/site-packages/anyio/to_thread.py\", line 63, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/opt/anaconda3/envs/hw_mps/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2502, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/anaconda3/envs/hw_mps/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 986, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/opt/anaconda3/envs/hw_mps/lib/python3.10/site-packages/gradio/utils.py\", line 1036, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/0d/v5wf93vd20j3t_d7spp38m5w0000gn/T/ipykernel_91851/2440359186.py\", line 619, in kylo_prediction_interactive\n",
      "    yoda_img = create_own_char()\n",
      "  File \"/var/folders/0d/v5wf93vd20j3t_d7spp38m5w0000gn/T/ipykernel_91851/2440359186.py\", line 111, in create_own_char\n",
      "    yoda[i, j] = np.array(colors[char]) / 255.0\n",
      "IndexError: index 16 is out of bounds for axis 1 with size 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://51fca8f245f5bd28a1.gradio.live\n"
     ]
    }
   ],
   "source": [
    "# Pedagogical Perceptron Learning Lab - Star Wars Edition\n",
    "!pip install gradio torch numpy matplotlib seaborn -q\n",
    "\n",
    "import gradio as gr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# PIXEL ART CHARACTERS\n",
    "# ============================================================\n",
    "\n",
    "def create_yoda():\n",
    "    \"\"\"Create a cute pixelated Yoda (16x16)\"\"\"\n",
    "    # Color palette: 0=transparent, 1=dark green, 2=light green, 3=brown (robe), 4=black (eyes), 5=white\n",
    "    yoda = np.zeros((16, 16, 4))\n",
    "\n",
    "    pixels = \"\"\"\n",
    "    ................\n",
    "    ....111..111....\n",
    "    ...1222112222...\n",
    "    ..122222222221..\n",
    "    ..122242244221..\n",
    "    .12222222222221.\n",
    "    .12222222222221.\n",
    "    ..122222222221..\n",
    "    ...12222222221..\n",
    "    ....33333333....\n",
    "    ...3333333333...\n",
    "    ..333333333333..\n",
    "    ..333333333333..\n",
    "    ...3333333333...\n",
    "    ....33333333....\n",
    "    ................\n",
    "    \"\"\"\n",
    "\n",
    "    colors = {\n",
    "        '.': [0, 0, 0, 0],           # Transparent\n",
    "        '1': [34, 85, 51, 255],       # Dark green (outline)\n",
    "        '2': [144, 190, 109, 255],    # Light green (skin)\n",
    "        '3': [139, 90, 43, 255],      # Brown (robe)\n",
    "        '4': [20, 20, 20, 255],       # Black (eyes)\n",
    "    }\n",
    "\n",
    "    rows = [r.strip() for r in pixels.strip().split('\\n')]\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, char in enumerate(row):\n",
    "            if char in colors:\n",
    "                yoda[i, j] = np.array(colors[char]) / 255.0\n",
    "\n",
    "    return yoda\n",
    "\n",
    "\n",
    "def create_own_char():\n",
    "    \"\"\"Create a cute pixelated Perry the Platypus (32x32)\"\"\"\n",
    "    # Color palette: 0=transparent, 1=dark green, 2=light green, 3=brown (robe), 4=black (eyes), 5=white\n",
    "    yoda = np.zeros((16, 16, 4))\n",
    "\n",
    "    pixels = \"\"\"\n",
    "    ................................\n",
    "    .....444444444.......4..........\n",
    "    ....44444444444444..444.........\n",
    "    ....44444444444444444444........\n",
    "    ....55555555555555555555........\n",
    "    ..444444444444444444444444......\n",
    "    ..444444444444444444444444......\n",
    "    ...1111111111111111111111.......\n",
    "    ...1111111111111111111111.......\n",
    "    ...1113333111111113333111.......\n",
    "    ...1111111111111111111111.......\n",
    "    ...1111222222222221111111.......\n",
    "    ...1111111222222221111111.......\n",
    "    ...111111111111111111111122222..\n",
    "    ...111111111111111111111122222..\n",
    "    ...11111111111111111111112222...\n",
    "    ...11111111111111111111112222...\n",
    "    ...11111111111111111111112222...\n",
    "    ...11111111111111111111112222...\n",
    "    ...1111111111111111111111222....\n",
    "    ...11111111111111111111112......\n",
    "    ...11111111111111111111112......\n",
    "    ..111111............111111......\n",
    "    ....1111............1111........\n",
    "    ..222222............22222.......\n",
    "    .22222................22222.....\n",
    "    ................................\n",
    "    ................................\n",
    "    ................................\n",
    "    ................................\n",
    "    ................................\n",
    "    \"\"\"\n",
    "\n",
    "    colors = {\n",
    "        '.': [0, 0, 0, 0],           # Transparent\n",
    "        '1': [31, 164, 51, 159],       # Dark green (outline)\n",
    "        '2': [243, 153, 10, 255],    # Light green (skin)\n",
    "        '3':[255,255,255,1],\n",
    "        '4': [139, 90, 43, 255],      # Brown (robe)\n",
    "        '5': [20, 20, 20, 255],       # Black (eyes)\n",
    "    }\n",
    "\n",
    "    rows = [r.strip() for r in pixels.strip().split('\\n')]\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, char in enumerate(row):\n",
    "            if char in colors:\n",
    "                yoda[i, j] = np.array(colors[char]) / 255.0\n",
    "\n",
    "    return yoda\n",
    "    \n",
    "\n",
    "def create_rey():\n",
    "    \"\"\"Create pixelated Rey (16x16)\"\"\"\n",
    "    rey = np.zeros((16, 16, 4))\n",
    "\n",
    "    pixels = \"\"\"\n",
    "    ....11111111....\n",
    "    ...1222222221...\n",
    "    ..122222222221..\n",
    "    ..122222222221..\n",
    "    ...1224224221...\n",
    "    ....12222221....\n",
    "    .....122221.....\n",
    "    ......3333......\n",
    "    .....333333.....\n",
    "    ....33333333....\n",
    "    ...3333333333...\n",
    "    ...3333333333...\n",
    "    ....33344333....\n",
    "    ....44....44....\n",
    "    ....44....44....\n",
    "    ................\n",
    "    \"\"\"\n",
    "\n",
    "    colors = {\n",
    "        '.': [0, 0, 0, 0],\n",
    "        '1': [101, 67, 33, 255],      # Brown (hair outline)\n",
    "        '2': [255, 218, 185, 255],    # Skin tone\n",
    "        '3': [210, 180, 140, 255],    # Tan (clothes)\n",
    "        '4': [101, 67, 33, 255],      # Brown (belt/boots)\n",
    "    }\n",
    "\n",
    "    rows = [r.strip() for r in pixels.strip().split('\\n')]\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, char in enumerate(row):\n",
    "            if char in colors:\n",
    "                rey[i, j] = np.array(colors[char]) / 255.0\n",
    "\n",
    "    return rey\n",
    "\n",
    "def create_luke():\n",
    "    \"\"\"Create pixelated Old Luke (16x16)\"\"\"\n",
    "    luke = np.zeros((16, 16, 4))\n",
    "\n",
    "    pixels = \"\"\"\n",
    "    ....11111111....\n",
    "    ...1555555551...\n",
    "    ..155555555551..\n",
    "    ..155555555551..\n",
    "    ...1554554551...\n",
    "    ....15555551....\n",
    "    ....15555551....\n",
    "    .....155551.....\n",
    "    ......3333......\n",
    "    .....333333.....\n",
    "    ....33333333....\n",
    "    ...3333333333...\n",
    "    ...3333333333...\n",
    "    ....33333333....\n",
    "    ....33....33....\n",
    "    ................\n",
    "    \"\"\"\n",
    "\n",
    "    colors = {\n",
    "        '.': [0, 0, 0, 0],\n",
    "        '1': [100, 100, 100, 255],    # Gray (outline)\n",
    "        '5': [200, 200, 200, 255],    # White/gray (hair/beard)\n",
    "        '3': [60, 50, 40, 255],       # Dark brown (robes)\n",
    "        '4': [50, 100, 150, 255],     # Blue (eyes)\n",
    "    }\n",
    "\n",
    "    rows = [r.strip() for r in pixels.strip().split('\\n')]\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, char in enumerate(row):\n",
    "            if char in colors:\n",
    "                luke[i, j] = np.array(colors[char]) / 255.0\n",
    "\n",
    "    return luke\n",
    "\n",
    "def create_kylo():\n",
    "    \"\"\"Create pixelated Kylo Ren (16x16)\"\"\"\n",
    "    kylo = np.zeros((16, 16, 4))\n",
    "\n",
    "    pixels = \"\"\"\n",
    "    ....11111111....\n",
    "    ...1111111111...\n",
    "    ..111111111111..\n",
    "    ..111111111111..\n",
    "    ...1114114111...\n",
    "    ....11111111....\n",
    "    .....111111.....\n",
    "    ......2222......\n",
    "    .....222222.....\n",
    "    ....22222222....\n",
    "    ...2222222222...\n",
    "    ...2222222222...\n",
    "    ...2222222222...\n",
    "    ....22222222....\n",
    "    ....22....22....\n",
    "    ................\n",
    "    \"\"\"\n",
    "\n",
    "    colors = {\n",
    "        '.': [0, 0, 0, 0],\n",
    "        '1': [30, 30, 30, 255],       # Black (hair/mask)\n",
    "        '2': [20, 20, 20, 255],       # Darker black (robes)\n",
    "        '4': [200, 50, 50, 255],      # Red (hint of sith)\n",
    "    }\n",
    "\n",
    "    rows = [r.strip() for r in pixels.strip().split('\\n')]\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, char in enumerate(row):\n",
    "            if char in colors:\n",
    "                kylo[i, j] = np.array(colors[char]) / 255.0\n",
    "\n",
    "    return kylo\n",
    "\n",
    "# ============================================================\n",
    "# 1. PERCEPTRON MODEL\n",
    "# ============================================================\n",
    "# Pay ATTENTION TO THIS BLOCK\n",
    "class Perceptron:\n",
    "    \"\"\"A simple perceptron for pedagogical purposes.\"\"\"\n",
    "\n",
    "    def __init__(self, n_inputs=2, activation='step'):\n",
    "        self.weights = np.random.randn(n_inputs) * 0.5\n",
    "        self.bias = np.random.randn() * 0.5\n",
    "        self.activation_name = activation\n",
    "\n",
    "    def set_weights(self, w1, w2, bias):\n",
    "        self.weights = np.array([w1, w2])\n",
    "        self.bias = bias\n",
    "\n",
    "    def activation(self, z):\n",
    "        if self.activation_name == 'step':\n",
    "            return np.where(z >= 0, 1, 0)\n",
    "        elif self.activation_name == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "        elif self.activation_name == 'tanh':\n",
    "            return np.tanh(z)\n",
    "        elif self.activation_name == 'relu':\n",
    "            return np.maximum(0, z)\n",
    "        elif self.activation_name == 'linear':\n",
    "            return z\n",
    "        else:\n",
    "            return z\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"Forward propagation: z = wÂ·x + b, a = activation(z)\"\"\"\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        return self.activation(z), z\n",
    "\n",
    "    def predict(self, X):\n",
    "        a, _ = self.forward(X)\n",
    "        return a\n",
    "\n",
    "# ============================================================\n",
    "# 2. VISUALIZATION FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def visualize_forward_propagation(x1, x2, w1, w2, bias, activation_fn):\n",
    "    \"\"\"Visualize the forward pass through a perceptron.\"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "    fig.patch.set_facecolor('#0d1117')\n",
    "\n",
    "    # Left: Network diagram\n",
    "    ax = axes[0]\n",
    "    ax.set_facecolor('#0d1117')\n",
    "    ax.set_xlim(-0.5, 3.5)\n",
    "    ax.set_ylim(-0.5, 2.5)\n",
    "\n",
    "    # Draw nodes\n",
    "    input_y = [1.8, 0.7]\n",
    "    colors_inputs = ['#4ecdc4', '#ff6b6b']\n",
    "\n",
    "    # Input nodes\n",
    "    for i, (y, val, color) in enumerate(zip(input_y, [x1, x2], colors_inputs)):\n",
    "        circle = plt.Circle((0.5, y), 0.25, color=color, ec='white', linewidth=2)\n",
    "        ax.add_patch(circle)\n",
    "        ax.text(0.5, y, f'x{i+1}\\n{val:.1f}', ha='center', va='center',\n",
    "                fontsize=10, fontweight='bold', color='white')\n",
    "\n",
    "    # Bias node\n",
    "    circle = plt.Circle((0.5, -0.1), 0.2, color='#ffd93d', ec='white', linewidth=2)\n",
    "    ax.add_patch(circle)\n",
    "    ax.text(0.5, -0.1, f'b\\n{bias:.1f}', ha='center', va='center',\n",
    "            fontsize=9, fontweight='bold', color='black')\n",
    "\n",
    "    # Sum node\n",
    "    circle = plt.Circle((2, 1.25), 0.3, color='#6c5ce7', ec='white', linewidth=2)\n",
    "    ax.add_patch(circle)\n",
    "    z = x1 * w1 + x2 * w2 + bias\n",
    "    ax.text(2, 1.25, f'Î£\\nz={z:.2f}', ha='center', va='center',\n",
    "            fontsize=9, fontweight='bold', color='white')\n",
    "\n",
    "    # Output node\n",
    "    perceptron = Perceptron(activation=activation_fn)\n",
    "    perceptron.set_weights(w1, w2, bias)\n",
    "    output, _ = perceptron.forward(np.array([[x1, x2]]))\n",
    "    output = output[0]\n",
    "\n",
    "    output_color = '#2ecc71' if output > 0.5 else '#e74c3c'\n",
    "    circle = plt.Circle((3, 1.25), 0.3, color=output_color, ec='white', linewidth=2)\n",
    "    ax.add_patch(circle)\n",
    "    ax.text(3, 1.25, f'Ïƒ\\n{output:.2f}', ha='center', va='center',\n",
    "            fontsize=9, fontweight='bold', color='white')\n",
    "\n",
    "    # Draw connections with weights\n",
    "    for i, (y, w, color) in enumerate(zip(input_y, [w1, w2], colors_inputs)):\n",
    "        ax.annotate('', xy=(1.7, 1.25), xytext=(0.75, y),\n",
    "                   arrowprops=dict(arrowstyle='->', color=color, lw=2))\n",
    "        mid_x, mid_y = (0.75 + 1.7)/2, (y + 1.25)/2\n",
    "        ax.text(mid_x, mid_y + 0.15, f'w{i+1}={w:.1f}', fontsize=9,\n",
    "                color=color, fontweight='bold', ha='center')\n",
    "\n",
    "    # Bias connection\n",
    "    ax.annotate('', xy=(1.7, 1.1), xytext=(0.7, 0.05),\n",
    "               arrowprops=dict(arrowstyle='->', color='#ffd93d', lw=2, ls='--'))\n",
    "\n",
    "    # Sum to activation\n",
    "    ax.annotate('', xy=(2.7, 1.25), xytext=(2.3, 1.25),\n",
    "               arrowprops=dict(arrowstyle='->', color='white', lw=2))\n",
    "\n",
    "    ax.set_title(f'Perceptron Network\\nActivation: {activation_fn}',\n",
    "                color='white', fontsize=12, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Middle: Computation breakdown\n",
    "    ax = axes[1]\n",
    "    ax.set_facecolor('#0d1117')\n",
    "    ax.axis('off')\n",
    "\n",
    "    computation_text = f\"\"\"\n",
    "    FORWARD PROPAGATION\n",
    "    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "    Step 1: Weighted Sum\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    z = wâ‚Â·xâ‚ + wâ‚‚Â·xâ‚‚ + b\n",
    "    z = ({w1:.1f})Â·({x1:.1f}) + ({w2:.1f})Â·({x2:.1f}) + ({bias:.1f})\n",
    "    z = {w1*x1:.2f} + {w2*x2:.2f} + {bias:.1f}\n",
    "    z = {z:.2f}\n",
    "\n",
    "    Step 2: Activation\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    a = {activation_fn}(z)\n",
    "    a = {activation_fn}({z:.2f})\n",
    "    a = {output:.4f}\n",
    "\n",
    "    Step 3: Decision\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    Output: {\"ðŸŸ¢ YES (Light Side)\" if output > 0.5 else \"ðŸ”´ NO (Dark Side)\"}\n",
    "    \"\"\"\n",
    "\n",
    "    ax.text(0.1, 0.95, computation_text, transform=ax.transAxes,\n",
    "           fontsize=11, fontfamily='monospace', color='#00ff88',\n",
    "           verticalalignment='top')\n",
    "\n",
    "    # Right: Activation function plot\n",
    "    ax = axes[2]\n",
    "    ax.set_facecolor('#161b22')\n",
    "\n",
    "    z_range = np.linspace(-5, 5, 200)\n",
    "    perceptron_temp = Perceptron(activation=activation_fn)\n",
    "    a_range = perceptron_temp.activation(z_range)\n",
    "\n",
    "    ax.plot(z_range, a_range, color='#00ff88', linewidth=3, label=f'{activation_fn}(z)')\n",
    "    ax.axvline(x=z, color='#ff6b6b', linestyle='--', linewidth=2, label=f'Your z = {z:.2f}')\n",
    "    ax.axhline(y=output, color='#4ecdc4', linestyle=':', linewidth=2)\n",
    "    ax.scatter([z], [output], color='#ffd93d', s=150, zorder=5, edgecolor='white', linewidth=2)\n",
    "\n",
    "    ax.set_xlabel('z (weighted sum)', color='white', fontsize=11)\n",
    "    ax.set_ylabel('a (activation output)', color='white', fontsize=11)\n",
    "    ax.set_title(f'{activation_fn.upper()} Activation Function', color='white', fontsize=12, fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.legend(facecolor='#161b22', edgecolor='white', labelcolor='white')\n",
    "    ax.grid(True, alpha=0.2, color='white')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def compare_activations(z_value):\n",
    "    \"\"\"Compare different activation functions side by side.\"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "    fig.patch.set_facecolor('#0d1117')\n",
    "\n",
    "    activations = {\n",
    "        'Step (Heaviside)': lambda z: np.where(z >= 0, 1, 0),\n",
    "        'Sigmoid': lambda z: 1 / (1 + np.exp(-np.clip(z, -500, 500))),\n",
    "        'Tanh': np.tanh,\n",
    "        'ReLU': lambda z: np.maximum(0, z),\n",
    "        'Leaky ReLU': lambda z: np.where(z > 0, z, 0.1 * z),\n",
    "        'Linear': lambda z: z\n",
    "    }\n",
    "\n",
    "    z_range = np.linspace(-5, 5, 200)\n",
    "\n",
    "    for ax, (name, func) in zip(axes.flat, activations.items()):\n",
    "        ax.set_facecolor('#161b22')\n",
    "\n",
    "        a_range = func(z_range)\n",
    "        a_point = func(z_value)\n",
    "\n",
    "        ax.plot(z_range, a_range, color='#00ff88', linewidth=3)\n",
    "        ax.axvline(x=0, color='white', alpha=0.3, linewidth=1)\n",
    "        ax.axhline(y=0, color='white', alpha=0.3, linewidth=1)\n",
    "        ax.axvline(x=z_value, color='#ff6b6b', linestyle='--', linewidth=2)\n",
    "        ax.scatter([z_value], [a_point], color='#ffd93d', s=120, zorder=5,\n",
    "                  edgecolor='white', linewidth=2)\n",
    "\n",
    "        ax.set_title(f'{name}\\nf({z_value:.1f}) = {a_point:.3f}',\n",
    "                    color='white', fontsize=11, fontweight='bold')\n",
    "        ax.tick_params(colors='white')\n",
    "        ax.spines['bottom'].set_color('white')\n",
    "        ax.spines['left'].set_color('white')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.set_xlabel('z', color='white')\n",
    "        ax.set_ylabel('f(z)', color='white')\n",
    "        ax.grid(True, alpha=0.2, color='white')\n",
    "\n",
    "    plt.suptitle('ðŸŽ¯ Activation Functions: How They Transform the Weighted Sum',\n",
    "                color='#00ff88', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def visualize_decision_boundary(w1, w2, bias, activation_fn):\n",
    "    \"\"\"Visualize the decision boundary created by the perceptron.\"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig.patch.set_facecolor('#0d1117')\n",
    "\n",
    "    # Create grid\n",
    "    x1_range = np.linspace(0, 10, 100)\n",
    "    x2_range = np.linspace(0, 10, 100)\n",
    "    X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "    perceptron = Perceptron(activation=activation_fn)\n",
    "    perceptron.set_weights(w1, w2, bias)\n",
    "\n",
    "    # Compute predictions for grid\n",
    "    grid_points = np.c_[X1.ravel(), X2.ravel()]\n",
    "    Z, _ = perceptron.forward(grid_points)\n",
    "    Z = Z.reshape(X1.shape)\n",
    "\n",
    "    # Left plot: Decision regions with Star Wars theme\n",
    "    ax = axes[0]\n",
    "    ax.set_facecolor('#161b22')\n",
    "\n",
    "    # Custom colormap: dark side (red) to light side (blue)\n",
    "    colors_dark_light = ['#8B0000', '#2c2c2c', '#1a1a2e', '#16213e', '#0f3460']\n",
    "    cmap_dark_light = LinearSegmentedColormap.from_list('darklight', colors_dark_light)\n",
    "\n",
    "    contour = ax.contourf(X1, X2, Z, levels=50, cmap=cmap_dark_light, alpha=0.8)\n",
    "\n",
    "    # Decision boundary line: w1*x1 + w2*x2 + b = 0\n",
    "    # x2 = (-w1*x1 - b) / w2\n",
    "    if abs(w2) > 0.001:\n",
    "        x1_line = np.linspace(0, 10, 100)\n",
    "        x2_line = (-w1 * x1_line - bias) / w2\n",
    "        valid = (x2_line >= 0) & (x2_line <= 10)\n",
    "        ax.plot(x1_line[valid], x2_line[valid], 'w-', linewidth=3,\n",
    "               label='Decision Boundary')\n",
    "        ax.plot(x1_line[valid], x2_line[valid], color='#ffd93d', linewidth=2,\n",
    "               linestyle='--')\n",
    "\n",
    "    ax.set_xlabel('xâ‚: Encounters with Rey â¤ï¸', color='white', fontsize=12)\n",
    "    ax.set_ylabel('xâ‚‚: Encounters with Luke ðŸ‘´', color='white', fontsize=12)\n",
    "    ax.set_title('Decision Boundary\\n\"Will Kylo Return to Light?\"',\n",
    "                color='white', fontsize=13, fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # Add character sprites\n",
    "    rey_img = create_rey()\n",
    "    luke_img = create_luke()\n",
    "\n",
    "    # Place Rey near x-axis label\n",
    "    ax_rey = fig.add_axes([0.35, 0.02, 0.06, 0.1])\n",
    "    ax_rey.imshow(rey_img, interpolation='nearest')\n",
    "    ax_rey.axis('off')\n",
    "\n",
    "    # Place Luke near y-axis label\n",
    "    ax_luke = fig.add_axes([0.02, 0.55, 0.06, 0.1])\n",
    "    ax_luke.imshow(luke_img, interpolation='nearest')\n",
    "    ax_luke.axis('off')\n",
    "\n",
    "    # Legend\n",
    "    dark_patch = mpatches.Patch(color='#8B0000', label='Dark Side ðŸ”´')\n",
    "    light_patch = mpatches.Patch(color='#0f3460', label='Light Side ðŸ”µ')\n",
    "    ax.legend(handles=[dark_patch, light_patch], loc='upper right',\n",
    "             facecolor='#161b22', edgecolor='white', labelcolor='white')\n",
    "\n",
    "    # Right plot: 3D surface\n",
    "    ax = axes[1]\n",
    "    ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    ax.set_facecolor('#0d1117')\n",
    "\n",
    "    surf = ax.plot_surface(X1, X2, Z, cmap=cmap_dark_light, alpha=0.8,\n",
    "                          edgecolor='none', antialiased=True)\n",
    "\n",
    "    ax.set_xlabel('xâ‚ (Rey)', color='white', fontsize=10)\n",
    "    ax.set_ylabel('xâ‚‚ (Luke)', color='white', fontsize=10)\n",
    "    ax.set_zlabel('Prediction', color='white', fontsize=10)\n",
    "    ax.set_title('Perceptron Output Surface', color='white', fontsize=12, fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.xaxis.pane.fill = False\n",
    "    ax.yaxis.pane.fill = False\n",
    "    ax.zaxis.pane.fill = False\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def kylo_prediction_interactive(rey_encounters, luke_encounters, w_rey, w_luke, bias, activation_fn):\n",
    "    \"\"\"Interactive Kylo Ren prediction with story.\"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    fig.patch.set_facecolor('#0d1117')\n",
    "\n",
    "    # Create perceptron\n",
    "    perceptron = Perceptron(activation=activation_fn)\n",
    "    perceptron.set_weights(w_rey, w_luke, bias)\n",
    "\n",
    "    X = np.array([[rey_encounters, luke_encounters]])\n",
    "    prediction, z = perceptron.forward(X)\n",
    "    prediction = prediction[0]\n",
    "    z = z[0]\n",
    "\n",
    "    # Main decision display\n",
    "    ax_main = fig.add_axes([0.3, 0.55, 0.4, 0.35])\n",
    "    ax_main.set_facecolor('#161b22')\n",
    "    ax_main.axis('off')\n",
    "\n",
    "    if prediction > 0.5:\n",
    "        result_color = '#4ecdc4'\n",
    "        result_text = \"âœ¨ RETURNS TO LIGHT âœ¨\"\n",
    "        story = \"The pull of love and legacy\\novercomes the darkness!\"\n",
    "    else:\n",
    "        result_color = '#e74c3c'\n",
    "        result_text = \"âš”ï¸ STAYS IN DARKNESS âš”ï¸\"\n",
    "        story = \"The dark side's grip\\nremains too strong...\"\n",
    "\n",
    "    ax_main.text(0.5, 0.7, result_text, transform=ax_main.transAxes,\n",
    "                fontsize=24, fontweight='bold', color=result_color,\n",
    "                ha='center', va='center')\n",
    "    ax_main.text(0.5, 0.35, story, transform=ax_main.transAxes,\n",
    "                fontsize=14, color='white', ha='center', va='center',\n",
    "                style='italic')\n",
    "    ax_main.text(0.5, 0.1, f'Confidence: {abs(prediction - 0.5) * 200:.1f}%',\n",
    "                transform=ax_main.transAxes, fontsize=12, color='#ffd93d',\n",
    "                ha='center', va='center')\n",
    "\n",
    "    # Character display\n",
    "    ax_kylo = fig.add_axes([0.42, 0.1, 0.16, 0.35])\n",
    "    kylo_img = create_kylo()\n",
    "    ax_kylo.imshow(kylo_img, interpolation='nearest')\n",
    "    ax_kylo.axis('off')\n",
    "    ax_kylo.set_title('Kylo Ren', color='white', fontsize=11)\n",
    "\n",
    "    ax_rey = fig.add_axes([0.1, 0.55, 0.12, 0.25])\n",
    "    rey_img = create_rey()\n",
    "    ax_rey.imshow(rey_img, interpolation='nearest')\n",
    "    ax_rey.axis('off')\n",
    "    ax_rey.set_title(f'Rey\\n{rey_encounters} encounters', color='#ff6b6b', fontsize=10)\n",
    "\n",
    "    ax_luke = fig.add_axes([0.1, 0.2, 0.12, 0.25])\n",
    "    luke_img = create_luke()\n",
    "    ax_luke.imshow(luke_img, interpolation='nearest')\n",
    "    ax_luke.axis('off')\n",
    "    ax_luke.set_title(f'Luke\\n{luke_encounters} encounters', color='#4ecdc4', fontsize=10)\n",
    "\n",
    "    # Computation panel\n",
    "    ax_comp = fig.add_axes([0.65, 0.1, 0.3, 0.35])\n",
    "    ax_comp.set_facecolor('#161b22')\n",
    "    ax_comp.axis('off')\n",
    "\n",
    "    comp_text = f\"\"\"\n",
    "    â•â• PERCEPTRON MATH â•â•\n",
    "\n",
    "    z = wâ‚Â·xâ‚ + wâ‚‚Â·xâ‚‚ + b\n",
    "    z = {w_rey:.1f}Ã—{rey_encounters} + {w_luke:.1f}Ã—{luke_encounters} + {bias:.1f}\n",
    "    z = {z:.2f}\n",
    "\n",
    "    a = {activation_fn}({z:.2f})\n",
    "    a = {prediction:.4f}\n",
    "\n",
    "    Decision threshold: 0.5\n",
    "    \"\"\"\n",
    "    ax_comp.text(0.05, 0.95, comp_text, transform=ax_comp.transAxes,\n",
    "                fontsize=10, fontfamily='monospace', color='#00ff88',\n",
    "                verticalalignment='top')\n",
    "\n",
    "    # Yoda wisdom\n",
    "    ax_yoda = fig.add_axes([0.78, 0.55, 0.12, 0.25])\n",
    "    # yoda_img = create_yoda()\n",
    "    yoda_img = create_own_char()\n",
    "    ax_yoda.imshow(yoda_img, interpolation='nearest')\n",
    "    ax_yoda.axis('off')\n",
    "\n",
    "    wisdoms = [\n",
    "        '\"Weighted sum,\\nthe Force is.\"',\n",
    "        '\"Learn the weights,\\nyou must.\"',\n",
    "        '\"Activation function,\\npowerful it is.\"'\n",
    "    ]\n",
    "    wisdom = wisdoms[int(prediction * 2.99)]\n",
    "    ax_yoda.text(0.5, -0.2, wisdom, transform=ax_yoda.transAxes,\n",
    "                fontsize=9, color='#90ee90', ha='center', style='italic')\n",
    "\n",
    "    # Title\n",
    "    fig.suptitle('â­ KYLO REN DESTINY PREDICTOR â­',\n",
    "                fontsize=18, fontweight='bold', color='#ffd93d', y=0.98)\n",
    "\n",
    "    return fig\n",
    "\n",
    "def perceptron_vs_regression(slope, intercept, threshold):\n",
    "    \"\"\"Compare perceptron classification with linear regression.\"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.patch.set_facecolor('#0d1117')\n",
    "\n",
    "    # Generate sample data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 50\n",
    "\n",
    "    # Class 0 (Dark side encounters)\n",
    "    X0 = np.random.randn(n_samples, 2) * 1.5 + [2, 2]\n",
    "    # Class 1 (Light side encounters)\n",
    "    X1 = np.random.randn(n_samples, 2) * 1.5 + [6, 6]\n",
    "\n",
    "    X = np.vstack([X0, X1])\n",
    "    y = np.array([0] * n_samples + [1] * n_samples)\n",
    "\n",
    "    # Left: Linear Regression\n",
    "    ax = axes[0]\n",
    "    ax.set_facecolor('#161b22')\n",
    "\n",
    "    # Simple linear regression on feature mean\n",
    "    X_mean = X.mean(axis=1)\n",
    "    from numpy.polynomial import polynomial as P\n",
    "    coeffs = np.polyfit(X_mean, y, 1)\n",
    "\n",
    "    ax.scatter(X0.mean(axis=1), [0]*n_samples, c='#e74c3c', s=60, alpha=0.7, label='Dark Side')\n",
    "    ax.scatter(X1.mean(axis=1), [1]*n_samples, c='#4ecdc4', s=60, alpha=0.7, label='Light Side')\n",
    "\n",
    "    x_line = np.linspace(0, 10, 100)\n",
    "    y_line = coeffs[0] * x_line + coeffs[1]\n",
    "    ax.plot(x_line, y_line, 'w-', linewidth=2, label='Linear Regression')\n",
    "    ax.plot(x_line, np.clip(y_line, 0, 1), '#ffd93d', linewidth=2, linestyle='--',\n",
    "           label='Clipped to [0,1]')\n",
    "\n",
    "    ax.axhline(y=0.5, color='#ff6b6b', linestyle=':', alpha=0.5)\n",
    "    ax.set_xlabel('Mean Features', color='white')\n",
    "    ax.set_ylabel('Prediction', color='white')\n",
    "    ax.set_title('Linear Regression\\n(Continuous Output)', color='white', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.legend(facecolor='#161b22', edgecolor='white', labelcolor='white', fontsize=8)\n",
    "    ax.set_ylim(-0.5, 1.5)\n",
    "\n",
    "    # Middle: Perceptron (Step)\n",
    "    ax = axes[1]\n",
    "    ax.set_facecolor('#161b22')\n",
    "\n",
    "    x1_range = np.linspace(0, 10, 100)\n",
    "    x2_range = np.linspace(0, 10, 100)\n",
    "    X1_grid, X2_grid = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "    # Decision boundary: slope * x1 - x2 + intercept = 0\n",
    "    Z_perceptron = np.where(slope * X1_grid - X2_grid + intercept >= 0, 1, 0)\n",
    "\n",
    "    ax.contourf(X1_grid, X2_grid, Z_perceptron, levels=[0, 0.5, 1],\n",
    "               colors=['#e74c3c', '#4ecdc4'], alpha=0.5)\n",
    "    ax.scatter(X0[:, 0], X0[:, 1], c='#e74c3c', s=60, edgecolor='white', label='Dark Side')\n",
    "    ax.scatter(X1[:, 0], X1[:, 1], c='#4ecdc4', s=60, edgecolor='white', label='Light Side')\n",
    "\n",
    "    # Decision boundary line\n",
    "    x1_boundary = np.linspace(0, 10, 100)\n",
    "    x2_boundary = slope * x1_boundary + intercept\n",
    "    valid = (x2_boundary >= 0) & (x2_boundary <= 10)\n",
    "    ax.plot(x1_boundary[valid], x2_boundary[valid], 'w-', linewidth=3)\n",
    "\n",
    "    ax.set_xlabel('xâ‚ (Rey encounters)', color='white')\n",
    "    ax.set_ylabel('xâ‚‚ (Luke encounters)', color='white')\n",
    "    ax.set_title('Perceptron (Step)\\n(Binary Output)', color='white', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.legend(facecolor='#161b22', edgecolor='white', labelcolor='white', fontsize=8)\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(0, 10)\n",
    "\n",
    "    # Right: Perceptron (Sigmoid) - Soft boundary\n",
    "    ax = axes[2]\n",
    "    ax.set_facecolor('#161b22')\n",
    "\n",
    "    Z_sigmoid = 1 / (1 + np.exp(-(slope * X1_grid - X2_grid + intercept)))\n",
    "\n",
    "    contour = ax.contourf(X1_grid, X2_grid, Z_sigmoid, levels=20, cmap='RdYlGn', alpha=0.7)\n",
    "    ax.scatter(X0[:, 0], X0[:, 1], c='#e74c3c', s=60, edgecolor='white', label='Dark Side')\n",
    "    ax.scatter(X1[:, 0], X1[:, 1], c='#4ecdc4', s=60, edgecolor='white', label='Light Side')\n",
    "    ax.plot(x1_boundary[valid], x2_boundary[valid], 'k-', linewidth=3, label='50% boundary')\n",
    "\n",
    "    ax.set_xlabel('xâ‚ (Rey encounters)', color='white')\n",
    "    ax.set_ylabel('xâ‚‚ (Luke encounters)', color='white')\n",
    "    ax.set_title('Perceptron (Sigmoid)\\n(Probability Output)', color='white', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.legend(facecolor='#161b22', edgecolor='white', labelcolor='white', fontsize=8)\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(0, 10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def train_perceptron_visualization(learning_rate, n_epochs):\n",
    "    \"\"\"Visualize perceptron training process.\"\"\"\n",
    "\n",
    "    # Generate linearly separable data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 30\n",
    "\n",
    "    X0 = np.random.randn(n_samples, 2) * 0.8 + [2, 5]\n",
    "    X1 = np.random.randn(n_samples, 2) * 0.8 + [5, 2]\n",
    "\n",
    "    X = np.vstack([X0, X1])\n",
    "    y = np.array([0] * n_samples + [1] * n_samples)\n",
    "\n",
    "    # Initialize weights\n",
    "    w = np.random.randn(2) * 0.5\n",
    "    b = np.random.randn() * 0.5\n",
    "\n",
    "    history = {'weights': [], 'bias': [], 'accuracy': [], 'loss': []}\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(int(n_epochs)):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            # Forward pass\n",
    "            z = np.dot(X[i], w) + b\n",
    "            pred = 1 / (1 + np.exp(-z))  # Sigmoid\n",
    "\n",
    "            # Loss\n",
    "            loss = -y[i] * np.log(pred + 1e-10) - (1 - y[i]) * np.log(1 - pred + 1e-10)\n",
    "            total_loss += loss\n",
    "\n",
    "            # Accuracy\n",
    "            if (pred > 0.5) == y[i]:\n",
    "                correct += 1\n",
    "\n",
    "            # Backpropagation\n",
    "            error = pred - y[i]\n",
    "            w -= learning_rate * error * X[i]\n",
    "            b -= learning_rate * error\n",
    "\n",
    "        history['weights'].append(w.copy())\n",
    "        history['bias'].append(b)\n",
    "        history['accuracy'].append(correct / len(X))\n",
    "        history['loss'].append(total_loss / len(X))\n",
    "\n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.patch.set_facecolor('#0d1117')\n",
    "\n",
    "    # Top Left: Final decision boundary\n",
    "    ax = axes[0, 0]\n",
    "    ax.set_facecolor('#161b22')\n",
    "\n",
    "    x1_range = np.linspace(0, 8, 100)\n",
    "    x2_range = np.linspace(0, 8, 100)\n",
    "    X1_grid, X2_grid = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "    Z = 1 / (1 + np.exp(-(w[0] * X1_grid + w[1] * X2_grid + b)))\n",
    "\n",
    "    ax.contourf(X1_grid, X2_grid, Z, levels=20, cmap='RdYlGn', alpha=0.7)\n",
    "    ax.scatter(X0[:, 0], X0[:, 1], c='#e74c3c', s=80, edgecolor='white', label='Class 0')\n",
    "    ax.scatter(X1[:, 0], X1[:, 1], c='#4ecdc4', s=80, edgecolor='white', label='Class 1')\n",
    "\n",
    "    # Decision boundary\n",
    "    if abs(w[1]) > 0.001:\n",
    "        x1_line = np.linspace(0, 8, 100)\n",
    "        x2_line = (-w[0] * x1_line - b) / w[1]\n",
    "        valid = (x2_line >= 0) & (x2_line <= 8)\n",
    "        ax.plot(x1_line[valid], x2_line[valid], 'w-', linewidth=3)\n",
    "\n",
    "    ax.set_xlabel('xâ‚', color='white')\n",
    "    ax.set_ylabel('xâ‚‚', color='white')\n",
    "    ax.set_title(f'Final Decision Boundary\\n(After {int(n_epochs)} epochs)',\n",
    "                color='white', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.legend(facecolor='#161b22', edgecolor='white', labelcolor='white')\n",
    "    ax.set_xlim(0, 8)\n",
    "    ax.set_ylim(0, 8)\n",
    "\n",
    "    # Top Right: Loss curve\n",
    "    ax = axes[0, 1]\n",
    "    ax.set_facecolor('#161b22')\n",
    "    ax.plot(history['loss'], color='#ff6b6b', linewidth=2)\n",
    "    ax.set_xlabel('Epoch', color='white')\n",
    "    ax.set_ylabel('Loss', color='white')\n",
    "    ax.set_title('Training Loss', color='white', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(True, alpha=0.2, color='white')\n",
    "\n",
    "    # Bottom Left: Accuracy curve\n",
    "    ax = axes[1, 0]\n",
    "    ax.set_facecolor('#161b22')\n",
    "    ax.plot([a * 100 for a in history['accuracy']], color='#4ecdc4', linewidth=2)\n",
    "    ax.set_xlabel('Epoch', color='white')\n",
    "    ax.set_ylabel('Accuracy (%)', color='white')\n",
    "    ax.set_title('Training Accuracy', color='white', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(True, alpha=0.2, color='white')\n",
    "    ax.set_ylim(0, 105)\n",
    "\n",
    "    # Bottom Right: Weight trajectory\n",
    "    ax = axes[1, 1]\n",
    "    ax.set_facecolor('#161b22')\n",
    "\n",
    "    w1_history = [ww[0] for ww in history['weights']]\n",
    "    w2_history = [ww[1] for ww in history['weights']]\n",
    "\n",
    "    ax.plot(w1_history, label='wâ‚', color='#ff6b6b', linewidth=2)\n",
    "    ax.plot(w2_history, label='wâ‚‚', color='#4ecdc4', linewidth=2)\n",
    "    ax.plot(history['bias'], label='bias', color='#ffd93d', linewidth=2, linestyle='--')\n",
    "\n",
    "    ax.set_xlabel('Epoch', color='white')\n",
    "    ax.set_ylabel('Value', color='white')\n",
    "    ax.set_title('Weight Evolution', color='white', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.legend(facecolor='#161b22', edgecolor='white', labelcolor='white')\n",
    "    ax.grid(True, alpha=0.2, color='white')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def show_nonlinearity_limitation():\n",
    "    \"\"\"Show XOR problem - perceptron limitation.\"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.patch.set_facecolor('#0d1117')\n",
    "\n",
    "    # XOR data\n",
    "    X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "    y_xor = np.array([0, 1, 1, 0])\n",
    "\n",
    "    # Left: XOR problem visualization\n",
    "    ax = axes[0]\n",
    "    ax.set_facecolor('#161b22')\n",
    "\n",
    "    colors = ['#e74c3c' if y == 0 else '#4ecdc4' for y in y_xor]\n",
    "    ax.scatter(X_xor[:, 0], X_xor[:, 1], c=colors, s=300, edgecolor='white', linewidth=2)\n",
    "\n",
    "    for i, (x, y, c) in enumerate(zip(X_xor[:, 0], X_xor[:, 1], y_xor)):\n",
    "        ax.annotate(f'({x},{y})â†’{c}', (x, y), textcoords=\"offset points\",\n",
    "                   xytext=(0, 15), ha='center', color='white', fontsize=10)\n",
    "\n",
    "    ax.set_xlabel('xâ‚', color='white', fontsize=12)\n",
    "    ax.set_ylabel('xâ‚‚', color='white', fontsize=12)\n",
    "    ax.set_title('XOR Problem\\n(Not Linearly Separable!)', color='#ff6b6b',\n",
    "                fontsize=13, fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.set_xlim(-0.5, 1.5)\n",
    "    ax.set_ylim(-0.5, 1.5)\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # Middle: Failed perceptron attempts\n",
    "    ax = axes[1]\n",
    "    ax.set_facecolor('#161b22')\n",
    "\n",
    "    ax.scatter(X_xor[:, 0], X_xor[:, 1], c=colors, s=200, edgecolor='white', linewidth=2)\n",
    "\n",
    "    # Show various failed lines\n",
    "    x_line = np.linspace(-0.5, 1.5, 100)\n",
    "\n",
    "    lines = [\n",
    "        (1, -0.5, 'Attempt 1'),\n",
    "        (-1, 0.5, 'Attempt 2'),\n",
    "        (0, 0.5, 'Attempt 3'),\n",
    "    ]\n",
    "\n",
    "    for slope, intercept, label in lines:\n",
    "        if slope != 0:\n",
    "            y_line = slope * x_line + intercept\n",
    "        else:\n",
    "            y_line = np.ones_like(x_line) * intercept\n",
    "        ax.plot(x_line, y_line, '--', alpha=0.5, linewidth=2, label=label)\n",
    "\n",
    "    ax.set_xlabel('xâ‚', color='white', fontsize=12)\n",
    "    ax.set_ylabel('xâ‚‚', color='white', fontsize=12)\n",
    "    ax.set_title('Single Perceptron FAILS\\n(No line can separate!)', color='#ffd93d',\n",
    "                fontsize=13, fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.set_xlim(-0.5, 1.5)\n",
    "    ax.set_ylim(-0.5, 1.5)\n",
    "    ax.legend(facecolor='#161b22', edgecolor='white', labelcolor='white', fontsize=8)\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # Right: Solution with 2 layers\n",
    "    ax = axes[2]\n",
    "    ax.set_facecolor('#161b22')\n",
    "\n",
    "    x1_range = np.linspace(-0.5, 1.5, 100)\n",
    "    x2_range = np.linspace(-0.5, 1.5, 100)\n",
    "    X1_grid, X2_grid = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "    # Two-layer network simulation\n",
    "    # Hidden layer with 2 neurons\n",
    "    h1 = 1 / (1 + np.exp(-(20 * X1_grid + 20 * X2_grid - 10)))  # x1 AND x2\n",
    "    h2 = 1 / (1 + np.exp(-(20 * X1_grid + 20 * X2_grid - 30)))  # high threshold\n",
    "\n",
    "    # Output: XOR = (x1 OR x2) AND NOT (x1 AND x2)\n",
    "    Z = 1 / (1 + np.exp(-(20 * h1 - 40 * h2 - 10)))\n",
    "\n",
    "    ax.contourf(X1_grid, X2_grid, Z, levels=20, cmap='RdYlGn', alpha=0.7)\n",
    "    ax.scatter(X_xor[:, 0], X_xor[:, 1], c=colors, s=200, edgecolor='white', linewidth=2)\n",
    "\n",
    "    ax.set_xlabel('xâ‚', color='white', fontsize=12)\n",
    "    ax.set_ylabel('xâ‚‚', color='white', fontsize=12)\n",
    "    ax.set_title('Multi-Layer Network WORKS!\\n(Neural Network)', color='#4ecdc4',\n",
    "                fontsize=13, fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.set_xlim(-0.5, 1.5)\n",
    "    ax.set_ylim(-0.5, 1.5)\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def visualize_boundary_gallery(boundary_type):\n",
    "    \"\"\"Show different types of decision boundaries with matching data.\"\"\"\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.patch.set_facecolor('#0d1117')\n",
    "\n",
    "    # Generate grid for decision boundary\n",
    "    x1_range = np.linspace(-3, 3, 200)\n",
    "    x2_range = np.linspace(-3, 3, 200)\n",
    "    X1_grid, X2_grid = np.meshgrid(x1_range, x2_range)\n",
    "    grid_points = np.c_[X1_grid.ravel(), X2_grid.ravel()]\n",
    "\n",
    "    # Different boundary types and their ideal data\n",
    "    if boundary_type == \"Linear (Perceptron)\":\n",
    "        # Linear boundary: w1*x1 + w2*x2 + b = 0\n",
    "        Z = (0.8 * X1_grid + 0.6 * X2_grid + 0.2)\n",
    "        Z = 1 / (1 + np.exp(-3 * Z))\n",
    "\n",
    "        # Linearly separable data\n",
    "        X0 = np.random.randn(40, 2) * 0.6 + [-1.2, -1]\n",
    "        X1 = np.random.randn(40, 2) * 0.6 + [1.2, 1]\n",
    "\n",
    "        title = \"LINEAR (Perceptron/Logistic)\"\n",
    "        equation = \"wâ‚xâ‚ + wâ‚‚xâ‚‚ + b = 0\"\n",
    "        description = \"Single straight line\\nPerfect for: linearly separable clusters\"\n",
    "        model_info = \"Model: Perceptron, Logistic Regression, Linear SVM\"\n",
    "        color_scheme = 'RdYlGn'\n",
    "\n",
    "    elif boundary_type == \"Circular (Radial)\":\n",
    "        # Circular boundary: x1Â² + x2Â² = rÂ²\n",
    "        Z = X1_grid**2 + X2_grid**2\n",
    "        Z = 1 / (1 + np.exp(-(Z - 2)))\n",
    "        Z = 1 - Z  # Invert so center is class 1\n",
    "\n",
    "        # Circular data - inner vs outer\n",
    "        r_inner = np.random.rand(40) * 1.0\n",
    "        theta_inner = np.random.rand(40) * 2 * np.pi\n",
    "        X1_pts = np.column_stack([r_inner * np.cos(theta_inner), r_inner * np.sin(theta_inner)])\n",
    "\n",
    "        r_outer = 1.8 + np.random.rand(40) * 0.8\n",
    "        theta_outer = np.random.rand(40) * 2 * np.pi\n",
    "        X0 = np.column_stack([r_outer * np.cos(theta_outer), r_outer * np.sin(theta_outer)])\n",
    "\n",
    "        title = \"CIRCULAR (Radial Basis)\"\n",
    "        equation = \"xâ‚Â² + xâ‚‚Â² = rÂ²\"\n",
    "        description = \"Circular/elliptical boundary\\nPerfect for: nested clusters, outlier detection\"\n",
    "        model_info = \"Model: RBF SVM, RBF Network, Polynomial features\"\n",
    "        color_scheme = 'RdYlGn'\n",
    "\n",
    "    elif boundary_type == \"Quadratic (Polynomial)\":\n",
    "        # Parabolic boundary: x2 = x1Â²\n",
    "        Z = X2_grid - (X1_grid**2 - 0.5)\n",
    "        Z = 1 / (1 + np.exp(-2 * Z))\n",
    "\n",
    "        # Data separated by parabola\n",
    "        X1_pts = np.random.randn(40, 2) * 0.5\n",
    "        X1_pts[:, 1] += X1_pts[:, 0]**2 + 0.8\n",
    "\n",
    "        X0 = np.random.randn(40, 2) * 0.5\n",
    "        X0[:, 1] += X0[:, 0]**2 - 1.5\n",
    "\n",
    "        title = \"QUADRATIC (Polynomial)\"\n",
    "        equation = \"xâ‚‚ = axâ‚Â² + bxâ‚ + c\"\n",
    "        description = \"Curved parabolic boundary\\nPerfect for: quadratic relationships\"\n",
    "        model_info = \"Model: Polynomial Regression, Quadratic SVM\"\n",
    "        color_scheme = 'RdYlGn'\n",
    "\n",
    "    elif boundary_type == \"XOR (Multi-region)\":\n",
    "        # XOR-like boundary\n",
    "        Z = np.sin(2 * X1_grid) * np.sin(2 * X2_grid)\n",
    "        Z = 1 / (1 + np.exp(-3 * Z))\n",
    "\n",
    "        # XOR-distributed data\n",
    "        X1_pts = np.vstack([\n",
    "            np.random.randn(20, 2) * 0.4 + [-1.5, 1.5],\n",
    "            np.random.randn(20, 2) * 0.4 + [1.5, -1.5]\n",
    "        ])\n",
    "        X0 = np.vstack([\n",
    "            np.random.randn(20, 2) * 0.4 + [-1.5, -1.5],\n",
    "            np.random.randn(20, 2) * 0.4 + [1.5, 1.5]\n",
    "        ])\n",
    "\n",
    "        title = \"XOR / CHECKERBOARD\"\n",
    "        equation = \"Multiple disconnected regions\"\n",
    "        description = \"Non-contiguous regions\\nPerfect for: XOR, checkerboard patterns\"\n",
    "        model_info = \"Model: MLP (2+ layers), Decision Tree, RBF SVM\"\n",
    "        color_scheme = 'RdYlGn'\n",
    "\n",
    "    elif boundary_type == \"Spiral (Highly Nonlinear)\":\n",
    "        # Spiral boundary\n",
    "        def spiral_score(x1, x2):\n",
    "            r = np.sqrt(x1**2 + x2**2)\n",
    "            theta = np.arctan2(x2, x1)\n",
    "            return np.sin(2 * theta + 2 * r)\n",
    "\n",
    "        Z = spiral_score(X1_grid, X2_grid)\n",
    "        Z = 1 / (1 + np.exp(-2 * Z))\n",
    "\n",
    "        # Spiral data\n",
    "        t1 = np.linspace(0, 3 * np.pi, 40)\n",
    "        r1 = 0.3 + t1 * 0.15\n",
    "        X1_pts = np.column_stack([r1 * np.cos(t1) + np.random.randn(40) * 0.15,\n",
    "                                   r1 * np.sin(t1) + np.random.randn(40) * 0.15])\n",
    "\n",
    "        t0 = np.linspace(0, 3 * np.pi, 40) + np.pi\n",
    "        r0 = 0.3 + t0 * 0.12\n",
    "        X0 = np.column_stack([r0 * np.cos(t0) + np.random.randn(40) * 0.15,\n",
    "                              r0 * np.sin(t0) + np.random.randn(40) * 0.15])\n",
    "\n",
    "        title = \"SPIRAL (Highly Nonlinear)\"\n",
    "        equation = \"f(r, Î¸) - complex function\"\n",
    "        description = \"Interleaved spiral arms\\nPerfect for: complex patterns, deep learning\"\n",
    "        model_info = \"Model: Deep Neural Network, KNN\"\n",
    "        color_scheme = 'RdYlGn'\n",
    "\n",
    "    else:  # Decision Tree / Rectangular\n",
    "        # Axis-aligned rectangular regions\n",
    "        Z = np.zeros_like(X1_grid)\n",
    "        Z[(X1_grid > 0) & (X2_grid > 0)] = 1\n",
    "        Z[(X1_grid < -1) & (X2_grid < 0)] = 1\n",
    "        Z[(X1_grid > 0.5) & (X1_grid < 1.5) & (X2_grid < -1)] = 1\n",
    "\n",
    "        # Data in rectangular regions\n",
    "        X1_pts = np.vstack([\n",
    "            np.random.rand(15, 2) * [1.5, 1.5] + [0.2, 0.2],\n",
    "            np.random.rand(15, 2) * [1, 1.5] + [-2.5, -1.5],\n",
    "            np.random.rand(10, 2) * [0.8, 0.8] + [0.6, -2]\n",
    "        ])\n",
    "        X0 = np.vstack([\n",
    "            np.random.rand(20, 2) * [1.5, 1.5] + [-2, 0.5],\n",
    "            np.random.rand(20, 2) * [2, 1.5] + [-0.5, -2]\n",
    "        ])\n",
    "\n",
    "        title = \"RECTANGULAR (Decision Tree)\"\n",
    "        equation = \"Axis-aligned splits\"\n",
    "        description = \"Rectangular regions\\nPerfect for: categorical features, interpretability\"\n",
    "        model_info = \"Model: Decision Tree, Random Forest\"\n",
    "        color_scheme = 'RdYlGn'\n",
    "\n",
    "    Z = Z.reshape(X1_grid.shape)\n",
    "\n",
    "    # Left: The ideal data for this boundary\n",
    "    ax = axes[0]\n",
    "    ax.set_facecolor('#161b22')\n",
    "    ax.scatter(X0[:, 0], X0[:, 1], c='#e74c3c', s=60, edgecolor='white', alpha=0.8, label='Class 0')\n",
    "    ax.scatter(X1_pts[:, 0], X1_pts[:, 1], c='#4ecdc4', s=60, edgecolor='white', alpha=0.8, label='Class 1')\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_ylim(-3, 3)\n",
    "    ax.set_xlabel('xâ‚', color='white')\n",
    "    ax.set_ylabel('xâ‚‚', color='white')\n",
    "    ax.set_title('DATA PATTERN\\n(What your data looks like)', color='#ffd93d', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.legend(facecolor='#161b22', edgecolor='white', labelcolor='white', fontsize=9)\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # Middle: The decision boundary\n",
    "    ax = axes[1]\n",
    "    ax.set_facecolor('#161b22')\n",
    "    contour = ax.contourf(X1_grid, X2_grid, Z, levels=20, cmap=color_scheme, alpha=0.8)\n",
    "    ax.contour(X1_grid, X2_grid, Z, levels=[0.5], colors='white', linewidths=3)\n",
    "    ax.scatter(X0[:, 0], X0[:, 1], c='#e74c3c', s=40, edgecolor='white', alpha=0.9)\n",
    "    ax.scatter(X1_pts[:, 0], X1_pts[:, 1], c='#4ecdc4', s=40, edgecolor='white', alpha=0.9)\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_ylim(-3, 3)\n",
    "    ax.set_xlabel('xâ‚', color='white')\n",
    "    ax.set_ylabel('xâ‚‚', color='white')\n",
    "    ax.set_title(f'{title}\\n{equation}', color='#00ff88', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # Right: Info panel\n",
    "    ax = axes[2]\n",
    "    ax.set_facecolor('#161b22')\n",
    "    ax.axis('off')\n",
    "\n",
    "    info_text = f\"\"\"\n",
    "    {title}\n",
    "    {'â•' * 30}\n",
    "\n",
    "    BOUNDARY SHAPE:\n",
    "    {description}\n",
    "\n",
    "    EQUATION FORM:\n",
    "    {equation}\n",
    "\n",
    "    MODELS THAT CREATE THIS:\n",
    "    {model_info}\n",
    "\n",
    "    KEY INSIGHT:\n",
    "    Match your model complexity\n",
    "    to your data complexity!\n",
    "\n",
    "    â€¢ Simple data â†’ Simple model\n",
    "    â€¢ Complex data â†’ Complex model\n",
    "    â€¢ But beware overfitting!\n",
    "    \"\"\"\n",
    "\n",
    "    ax.text(0.05, 0.95, info_text, transform=ax.transAxes,\n",
    "           fontsize=11, fontfamily='monospace', color='#00ff88',\n",
    "           verticalalignment='top', linespacing=1.5)\n",
    "\n",
    "    plt.suptitle('ðŸŽ¯ DECISION BOUNDARY GALLERY: Match Model to Data!',\n",
    "                color='#ffd93d', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def compare_all_boundaries():\n",
    "    \"\"\"Show all boundary types in one view for comparison.\"\"\"\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.patch.set_facecolor('#0d1117')\n",
    "\n",
    "    x1_range = np.linspace(-3, 3, 150)\n",
    "    x2_range = np.linspace(-3, 3, 150)\n",
    "    X1_grid, X2_grid = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "    boundaries = [\n",
    "        (\"Linear\", 1 / (1 + np.exp(-3 * (0.8 * X1_grid + 0.6 * X2_grid))),\n",
    "         \"Perceptron\\nLogistic Reg.\", \"Straight line\"),\n",
    "        (\"Circular\", 1 - 1 / (1 + np.exp(-(X1_grid**2 + X2_grid**2 - 2))),\n",
    "         \"RBF SVM\\nRBF Network\", \"Circle/Ellipse\"),\n",
    "        (\"Quadratic\", 1 / (1 + np.exp(-2 * (X2_grid - X1_grid**2 + 0.5))),\n",
    "         \"Polynomial\\nFeatures\", \"Parabola\"),\n",
    "        (\"XOR\", 1 / (1 + np.exp(-3 * np.sin(2*X1_grid) * np.sin(2*X2_grid))),\n",
    "         \"MLP\\nDecision Tree\", \"Multi-region\"),\n",
    "        (\"Spiral\", 1 / (1 + np.exp(-2 * np.sin(2*np.arctan2(X2_grid, X1_grid) + 2*np.sqrt(X1_grid**2 + X2_grid**2)))),\n",
    "         \"Deep NN\\nKNN\", \"Complex curves\"),\n",
    "        (\"Rectangular\", None,  # Special case\n",
    "         \"Decision Tree\\nRandom Forest\", \"Axis-aligned\"),\n",
    "    ]\n",
    "\n",
    "    for ax, (name, Z, models, shape) in zip(axes.flat, boundaries):\n",
    "        ax.set_facecolor('#161b22')\n",
    "\n",
    "        if name == \"Rectangular\":\n",
    "            Z = np.zeros_like(X1_grid)\n",
    "            Z[(X1_grid > 0) & (X2_grid > 0)] = 1\n",
    "            Z[(X1_grid < -1) & (X2_grid < 0)] = 1\n",
    "\n",
    "        ax.contourf(X1_grid, X2_grid, Z, levels=20, cmap='RdYlGn', alpha=0.8)\n",
    "        ax.contour(X1_grid, X2_grid, Z, levels=[0.5], colors='white', linewidths=2)\n",
    "\n",
    "        ax.set_xlim(-3, 3)\n",
    "        ax.set_ylim(-3, 3)\n",
    "        ax.set_title(f'{name}\\n{shape}', color='#00ff88', fontweight='bold', fontsize=11)\n",
    "        ax.set_xlabel(models, color='#ffd93d', fontsize=9)\n",
    "        ax.tick_params(colors='white', labelsize=8)\n",
    "        ax.spines['bottom'].set_color('white')\n",
    "        ax.spines['left'].set_color('white')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "    plt.suptitle('ðŸ”® DECISION BOUNDARY ZOO: What Different Models Can Learn',\n",
    "                color='#ffd93d', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ============================================================\n",
    "# GRADIENT DESCENT EDUCATION\n",
    "# ============================================================\n",
    "\n",
    "def visualize_gradient_computation(x_val, target_val, w_init, b_init, learning_rate):\n",
    "    \"\"\"\n",
    "    Show step-by-step gradient computation: forward pass, loss, backward pass, update.\n",
    "    Following the pedagogical approach from the autograd tutorial.\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    fig.patch.set_facecolor('#0d1117')\n",
    "\n",
    "    # Current values\n",
    "    w = w_init\n",
    "    b = b_init\n",
    "    x = x_val\n",
    "    target = target_val\n",
    "    lr = learning_rate\n",
    "\n",
    "    # ===== FORWARD PASS =====\n",
    "    y_pred = w * x + b\n",
    "    loss = (y_pred - target) ** 2\n",
    "\n",
    "    # ===== BACKWARD PASS (Manual Gradient Computation) =====\n",
    "    # Chain rule:\n",
    "    # dL/dw = dL/dy_pred * dy_pred/dw\n",
    "    # dL/dy_pred = 2 * (y_pred - target)\n",
    "    # dy_pred/dw = x\n",
    "    # Therefore: dL/dw = 2 * (y_pred - target) * x\n",
    "\n",
    "    dL_dy_pred = 2 * (y_pred - target)\n",
    "    dy_pred_dw = x\n",
    "    dy_pred_db = 1\n",
    "\n",
    "    dL_dw = dL_dy_pred * dy_pred_dw\n",
    "    dL_db = dL_dy_pred * dy_pred_db\n",
    "\n",
    "    # ===== UPDATE =====\n",
    "    w_new = w - lr * dL_dw\n",
    "    b_new = b - lr * dL_db\n",
    "\n",
    "    # New prediction after update\n",
    "    y_pred_new = w_new * x + b_new\n",
    "    loss_new = (y_pred_new - target) ** 2\n",
    "\n",
    "    # ===== VISUALIZATION =====\n",
    "\n",
    "    # Panel 1: Forward Pass Diagram\n",
    "    ax1 = fig.add_axes([0.02, 0.55, 0.3, 0.4])\n",
    "    ax1.set_facecolor('#161b22')\n",
    "    ax1.set_xlim(-0.5, 4.5)\n",
    "    ax1.set_ylim(-0.5, 3)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('â‘  FORWARD PASS', color='#00ff88', fontsize=14, fontweight='bold', pad=10)\n",
    "\n",
    "    # Draw nodes\n",
    "    # Input x\n",
    "    circle = plt.Circle((0.5, 2), 0.3, color='#4ecdc4', ec='white', linewidth=2)\n",
    "    ax1.add_patch(circle)\n",
    "    ax1.text(0.5, 2, f'x\\n{x:.1f}', ha='center', va='center', fontsize=10, fontweight='bold', color='white')\n",
    "\n",
    "    # Weight w\n",
    "    rect = plt.Rectangle((1.3, 1.7), 0.6, 0.6, color='#ff6b6b', ec='white', linewidth=2)\n",
    "    ax1.add_patch(rect)\n",
    "    ax1.text(1.6, 2, f'w\\n{w:.2f}', ha='center', va='center', fontsize=9, fontweight='bold', color='white')\n",
    "\n",
    "    # Multiplication result\n",
    "    ax1.text(2.5, 2.3, f'wÂ·x = {w*x:.2f}', ha='center', va='center', fontsize=9, color='#ffd93d')\n",
    "\n",
    "    # Bias b\n",
    "    circle = plt.Circle((2.5, 1), 0.25, color='#ffd93d', ec='white', linewidth=2)\n",
    "    ax1.add_patch(circle)\n",
    "    ax1.text(2.5, 1, f'b\\n{b:.2f}', ha='center', va='center', fontsize=9, fontweight='bold', color='black')\n",
    "\n",
    "    # Sum node\n",
    "    circle = plt.Circle((3.2, 1.5), 0.3, color='#6c5ce7', ec='white', linewidth=2)\n",
    "    ax1.add_patch(circle)\n",
    "    ax1.text(3.2, 1.5, f'Å·\\n{y_pred:.2f}', ha='center', va='center', fontsize=9, fontweight='bold', color='white')\n",
    "\n",
    "    # Target\n",
    "    circle = plt.Circle((4, 2.3), 0.25, color='#2ecc71', ec='white', linewidth=2)\n",
    "    ax1.add_patch(circle)\n",
    "    ax1.text(4, 2.3, f'y\\n{target:.1f}', ha='center', va='center', fontsize=9, fontweight='bold', color='white')\n",
    "\n",
    "    # Loss\n",
    "    rect = plt.Rectangle((3.6, 0.3), 0.8, 0.5, color='#e74c3c', ec='white', linewidth=2)\n",
    "    ax1.add_patch(rect)\n",
    "    ax1.text(4, 0.55, f'L\\n{loss:.2f}', ha='center', va='center', fontsize=9, fontweight='bold', color='white')\n",
    "\n",
    "    # Arrows\n",
    "    ax1.annotate('', xy=(1.3, 2), xytext=(0.8, 2), arrowprops=dict(arrowstyle='->', color='white', lw=1.5))\n",
    "    ax1.annotate('', xy=(2.9, 1.6), xytext=(1.9, 2), arrowprops=dict(arrowstyle='->', color='white', lw=1.5))\n",
    "    ax1.annotate('', xy=(2.9, 1.4), xytext=(2.75, 1.1), arrowprops=dict(arrowstyle='->', color='white', lw=1.5))\n",
    "    ax1.annotate('', xy=(3.7, 0.6), xytext=(3.5, 1.3), arrowprops=dict(arrowstyle='->', color='white', lw=1.5))\n",
    "    ax1.annotate('', xy=(3.85, 0.8), xytext=(3.85, 2.05), arrowprops=dict(arrowstyle='->', color='white', lw=1.5))\n",
    "\n",
    "    # Panel 2: Math Equations (Forward)\n",
    "    ax2 = fig.add_axes([0.34, 0.55, 0.3, 0.4])\n",
    "    ax2.set_facecolor('#161b22')\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title('FORWARD PASS MATH', color='#00ff88', fontsize=12, fontweight='bold')\n",
    "\n",
    "    forward_text = f\"\"\"\n",
    "    Step 1: Linear Combination\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    Å· = w Â· x + b\n",
    "    Å· = {w:.2f} Ã— {x:.1f} + {b:.2f}\n",
    "    Å· = {w*x:.2f} + {b:.2f}\n",
    "    Å· = {y_pred:.2f}\n",
    "\n",
    "    Step 2: Loss (MSE)\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    L = (Å· - y)Â²\n",
    "    L = ({y_pred:.2f} - {target:.1f})Â²\n",
    "    L = ({y_pred - target:.2f})Â²\n",
    "    L = {loss:.4f}\n",
    "    \"\"\"\n",
    "    ax2.text(0.05, 0.95, forward_text, transform=ax2.transAxes, fontsize=10,\n",
    "            fontfamily='monospace', color='#4ecdc4', verticalalignment='top')\n",
    "\n",
    "    # Panel 3: Backward Pass (Chain Rule)\n",
    "    ax3 = fig.add_axes([0.66, 0.55, 0.32, 0.4])\n",
    "    ax3.set_facecolor('#161b22')\n",
    "    ax3.axis('off')\n",
    "    ax3.set_title('â‘¡ BACKWARD PASS (Chain Rule)', color='#ff6b6b', fontsize=14, fontweight='bold')\n",
    "\n",
    "    backward_text = f\"\"\"\n",
    "    Goal: Find âˆ‚L/âˆ‚w and âˆ‚L/âˆ‚b\n",
    "\n",
    "    Chain Rule for âˆ‚L/âˆ‚w:\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚Å·  Ã—  âˆ‚Å·/âˆ‚w\n",
    "\n",
    "    âˆ‚L/âˆ‚Å· = 2(Å· - y) = 2({y_pred:.2f} - {target:.1f}) = {dL_dy_pred:.2f}\n",
    "    âˆ‚Å·/âˆ‚w = x = {x:.1f}\n",
    "\n",
    "    âˆ‚L/âˆ‚w = {dL_dy_pred:.2f} Ã— {x:.1f} = {dL_dw:.2f}\n",
    "\n",
    "    Chain Rule for âˆ‚L/âˆ‚b:\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    âˆ‚L/âˆ‚b = âˆ‚L/âˆ‚Å·  Ã—  âˆ‚Å·/âˆ‚b\n",
    "\n",
    "    âˆ‚Å·/âˆ‚b = 1\n",
    "    âˆ‚L/âˆ‚b = {dL_dy_pred:.2f} Ã— 1 = {dL_db:.2f}\n",
    "    \"\"\"\n",
    "    ax3.text(0.02, 0.95, backward_text, transform=ax3.transAxes, fontsize=9,\n",
    "            fontfamily='monospace', color='#ff6b6b', verticalalignment='top')\n",
    "\n",
    "    # Panel 4: Weight Update Comparison\n",
    "    ax4 = fig.add_axes([0.02, 0.08, 0.45, 0.4])\n",
    "    ax4.set_facecolor('#161b22')\n",
    "    ax4.axis('off')\n",
    "    ax4.set_title('â‘¢ WEIGHT UPDATE', color='#ffd93d', fontsize=14, fontweight='bold')\n",
    "\n",
    "    update_text = f\"\"\"\n",
    "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    â•‘  MANUAL UPDATE (What we do by hand)                       â•‘\n",
    "    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "    â•‘                                                           â•‘\n",
    "    â•‘  w_new = w - lr Ã— âˆ‚L/âˆ‚w                                   â•‘\n",
    "    â•‘  w_new = {w:.2f} - {lr} Ã— {dL_dw:.2f}                           â•‘\n",
    "    â•‘  w_new = {w:.2f} - {lr * dL_dw:.4f}                              â•‘\n",
    "    â•‘  w_new = {w_new:.4f}                                         â•‘\n",
    "    â•‘                                                           â•‘\n",
    "    â•‘  b_new = b - lr Ã— âˆ‚L/âˆ‚b                                   â•‘\n",
    "    â•‘  b_new = {b:.2f} - {lr} Ã— {dL_db:.2f}                           â•‘\n",
    "    â•‘  b_new = {b_new:.4f}                                         â•‘\n",
    "    â•‘                                                           â•‘\n",
    "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    â•‘  PyTorch AUTOGRAD (What the library does)                 â•‘\n",
    "    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "    â•‘                                                           â•‘\n",
    "    â•‘  loss.backward()     # Computes ALL gradients!            â•‘\n",
    "    â•‘  optimizer.step()    # Updates ALL weights!               â•‘\n",
    "    â•‘  optimizer.zero_grad() # Resets gradients                 â•‘\n",
    "    â•‘                                                           â•‘\n",
    "    â•‘  That's it! No manual derivatives needed.                 â•‘\n",
    "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    \"\"\"\n",
    "    ax4.text(0.02, 0.98, update_text, transform=ax4.transAxes, fontsize=9,\n",
    "            fontfamily='monospace', color='#ffd93d', verticalalignment='top')\n",
    "\n",
    "    # Panel 5: Before/After Visualization\n",
    "    ax5 = fig.add_axes([0.52, 0.08, 0.45, 0.4])\n",
    "    ax5.set_facecolor('#161b22')\n",
    "\n",
    "    # Show the line before and after\n",
    "    x_range = np.linspace(0, max(x * 1.5, 5), 100)\n",
    "    y_before = w * x_range + b\n",
    "    y_after = w_new * x_range + b_new\n",
    "\n",
    "    ax5.plot(x_range, y_before, 'r--', linewidth=2, label=f'Before: y = {w:.2f}x + {b:.2f}', alpha=0.7)\n",
    "    ax5.plot(x_range, y_after, 'g-', linewidth=2, label=f'After: y = {w_new:.2f}x + {b_new:.2f}')\n",
    "\n",
    "    # Mark the target point\n",
    "    ax5.scatter([x], [target], c='#ffd93d', s=200, zorder=5, edgecolor='white', linewidth=2, label=f'Target ({x}, {target})')\n",
    "    ax5.scatter([x], [y_pred], c='#e74c3c', s=100, marker='x', zorder=5, linewidth=3, label=f'Before pred: {y_pred:.2f}')\n",
    "    ax5.scatter([x], [y_pred_new], c='#2ecc71', s=100, marker='o', zorder=5, edgecolor='white', label=f'After pred: {y_pred_new:.2f}')\n",
    "\n",
    "    # Draw error bars\n",
    "    ax5.plot([x, x], [y_pred, target], 'r:', linewidth=2, alpha=0.7)\n",
    "    ax5.plot([x, x], [y_pred_new, target], 'g:', linewidth=2, alpha=0.7)\n",
    "\n",
    "    ax5.set_xlabel('x', color='white', fontsize=11)\n",
    "    ax5.set_ylabel('y', color='white', fontsize=11)\n",
    "    ax5.set_title(f'RESULT: Loss {loss:.2f} â†’ {loss_new:.2f} (â†“{(loss-loss_new)/loss*100:.1f}%)',\n",
    "                 color='#2ecc71' if loss_new < loss else '#e74c3c', fontsize=12, fontweight='bold')\n",
    "    ax5.tick_params(colors='white')\n",
    "    ax5.legend(facecolor='#161b22', edgecolor='white', labelcolor='white', fontsize=8, loc='upper left')\n",
    "    ax5.spines['bottom'].set_color('white')\n",
    "    ax5.spines['left'].set_color('white')\n",
    "    ax5.spines['top'].set_visible(False)\n",
    "    ax5.spines['right'].set_visible(False)\n",
    "    ax5.grid(True, alpha=0.2, color='white')\n",
    "    ax5.set_xlim(0, max(x * 1.5, 5))\n",
    "    ax5.set_ylim(min(0, y_pred - 2, y_after.min()), max(target + 2, y_before.max()))\n",
    "\n",
    "    plt.suptitle('ðŸŽ“ GRADIENT DESCENT: Manual vs Autograd',\n",
    "                color='#00ff88', fontsize=16, fontweight='bold', y=0.98)\n",
    "\n",
    "    return fig\n",
    "\n",
    "def visualize_training_steps(x_val, target_val, w_init, b_init, learning_rate, n_steps):\n",
    "    \"\"\"Show multiple training steps to see convergence.\"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.patch.set_facecolor('#0d1117')\n",
    "\n",
    "    # Training loop\n",
    "    w = w_init\n",
    "    b = b_init\n",
    "    x = x_val\n",
    "    target = target_val\n",
    "    lr = learning_rate\n",
    "\n",
    "    history = {'w': [w], 'b': [b], 'loss': [], 'y_pred': []}\n",
    "\n",
    "    for step in range(int(n_steps)):\n",
    "        # Forward\n",
    "        y_pred = w * x + b\n",
    "        loss = (y_pred - target) ** 2\n",
    "\n",
    "        # Backward\n",
    "        dL_dw = 2 * (y_pred - target) * x\n",
    "        dL_db = 2 * (y_pred - target)\n",
    "\n",
    "        # Update\n",
    "        w = w - lr * dL_dw\n",
    "        b = b - lr * dL_db\n",
    "\n",
    "        history['w'].append(w)\n",
    "        history['b'].append(b)\n",
    "        history['loss'].append(loss)\n",
    "        history['y_pred'].append(y_pred)\n",
    "\n",
    "    # Final prediction\n",
    "    y_pred_final = w * x + b\n",
    "    loss_final = (y_pred_final - target) ** 2\n",
    "    history['loss'].append(loss_final)\n",
    "    history['y_pred'].append(y_pred_final)\n",
    "\n",
    "    # Plot 1: Loss over time\n",
    "    ax = axes[0, 0]\n",
    "    ax.set_facecolor('#161b22')\n",
    "    ax.plot(history['loss'], color='#ff6b6b', linewidth=2, marker='o', markersize=4)\n",
    "    ax.set_xlabel('Step', color='white')\n",
    "    ax.set_ylabel('Loss', color='white')\n",
    "    ax.set_title('Loss Over Training Steps', color='#00ff88', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(True, alpha=0.2, color='white')\n",
    "\n",
    "    # Plot 2: Weight trajectory\n",
    "    ax = axes[0, 1]\n",
    "    ax.set_facecolor('#161b22')\n",
    "    ax.plot(history['w'], color='#4ecdc4', linewidth=2, marker='o', markersize=4, label='w')\n",
    "    ax.plot(history['b'], color='#ffd93d', linewidth=2, marker='s', markersize=4, label='b')\n",
    "    ax.axhline(y=target/x, color='#4ecdc4', linestyle='--', alpha=0.5, label=f'Optimal w â‰ˆ {target/x:.2f}')\n",
    "    ax.set_xlabel('Step', color='white')\n",
    "    ax.set_ylabel('Value', color='white')\n",
    "    ax.set_title('Weight & Bias Over Time', color='#00ff88', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.legend(facecolor='#161b22', edgecolor='white', labelcolor='white', fontsize=9)\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(True, alpha=0.2, color='white')\n",
    "\n",
    "    # Plot 3: Prediction approaching target\n",
    "    ax = axes[1, 0]\n",
    "    ax.set_facecolor('#161b22')\n",
    "    ax.plot(history['y_pred'], color='#6c5ce7', linewidth=2, marker='o', markersize=4, label='Prediction')\n",
    "    ax.axhline(y=target, color='#2ecc71', linestyle='--', linewidth=2, label=f'Target = {target}')\n",
    "    ax.fill_between(range(len(history['y_pred'])), history['y_pred'], [target]*len(history['y_pred']),\n",
    "                   alpha=0.2, color='#ff6b6b')\n",
    "    ax.set_xlabel('Step', color='white')\n",
    "    ax.set_ylabel('Å·', color='white')\n",
    "    ax.set_title('Prediction Approaching Target', color='#00ff88', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.legend(facecolor='#161b22', edgecolor='white', labelcolor='white', fontsize=9)\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(True, alpha=0.2, color='white')\n",
    "\n",
    "    # Plot 4: Line evolution\n",
    "    ax = axes[1, 1]\n",
    "    ax.set_facecolor('#161b22')\n",
    "\n",
    "    x_range = np.linspace(0, max(x * 1.5, 5), 100)\n",
    "\n",
    "    # Plot lines at different steps\n",
    "    n_lines = min(10, int(n_steps))\n",
    "    step_indices = np.linspace(0, len(history['w'])-1, n_lines, dtype=int)\n",
    "\n",
    "    colors = plt.cm.coolwarm(np.linspace(0, 1, n_lines))\n",
    "\n",
    "    for i, idx in enumerate(step_indices):\n",
    "        y_line = history['w'][idx] * x_range + history['b'][idx]\n",
    "        alpha = 0.3 if idx < len(history['w'])-1 else 1.0\n",
    "        lw = 1 if idx < len(history['w'])-1 else 3\n",
    "        ax.plot(x_range, y_line, color=colors[i], alpha=alpha, linewidth=lw)\n",
    "\n",
    "    ax.scatter([x], [target], c='#ffd93d', s=200, zorder=10, edgecolor='white', linewidth=2, label='Target')\n",
    "\n",
    "    ax.set_xlabel('x', color='white')\n",
    "    ax.set_ylabel('y', color='white')\n",
    "    ax.set_title('Line Evolution (Redâ†’Blue = Earlyâ†’Late)', color='#00ff88', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.legend(facecolor='#161b22', edgecolor='white', labelcolor='white', fontsize=9)\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(True, alpha=0.2, color='white')\n",
    "    ax.set_xlim(0, max(x * 1.5, 5))\n",
    "\n",
    "    plt.suptitle(f'ðŸ“ˆ TRAINING CONVERGENCE: {int(n_steps)} Steps | Final Loss: {loss_final:.6f}',\n",
    "                color='#ffd93d', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def show_gradient_accumulation_problem():\n",
    "    \"\"\"Demonstrate why we need to zero gradients.\"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.patch.set_facecolor('#0d1117')\n",
    "\n",
    "    # Simulate gradient accumulation problem\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Correct training (zeroing gradients)\n",
    "    w_correct = 1.0\n",
    "    lr = 0.1\n",
    "    x, target = 2.0, 10.0\n",
    "\n",
    "    history_correct = [w_correct]\n",
    "    for _ in range(20):\n",
    "        y_pred = w_correct * x\n",
    "        grad = 2 * (y_pred - target) * x\n",
    "        w_correct = w_correct - lr * grad  # Fresh gradient each time\n",
    "        history_correct.append(w_correct)\n",
    "\n",
    "    # Wrong training (accumulating gradients)\n",
    "    w_wrong = 1.0\n",
    "    accumulated_grad = 0\n",
    "\n",
    "    history_wrong = [w_wrong]\n",
    "    for _ in range(20):\n",
    "        y_pred = w_wrong * x\n",
    "        grad = 2 * (y_pred - target) * x\n",
    "        accumulated_grad += grad  # BUG: accumulating!\n",
    "        w_wrong = w_wrong - lr * accumulated_grad\n",
    "        history_wrong.append(w_wrong)\n",
    "\n",
    "    # Plot 1: Correct training\n",
    "    ax = axes[0]\n",
    "    ax.set_facecolor('#161b22')\n",
    "    ax.plot(history_correct, color='#2ecc71', linewidth=2, marker='o', markersize=4)\n",
    "    ax.axhline(y=target/x, color='#ffd93d', linestyle='--', label=f'Optimal w = {target/x}')\n",
    "    ax.set_xlabel('Step', color='white')\n",
    "    ax.set_ylabel('w', color='white')\n",
    "    ax.set_title('âœ… CORRECT: Zero Gradients Each Step', color='#2ecc71', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.legend(facecolor='#161b22', edgecolor='white', labelcolor='white')\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(True, alpha=0.2, color='white')\n",
    "\n",
    "    # Plot 2: Wrong training (explodes!)\n",
    "    ax = axes[1]\n",
    "    ax.set_facecolor('#161b22')\n",
    "    ax.plot(history_wrong[:15], color='#e74c3c', linewidth=2, marker='o', markersize=4)\n",
    "    ax.set_xlabel('Step', color='white')\n",
    "    ax.set_ylabel('w', color='white')\n",
    "    ax.set_title('âŒ WRONG: Accumulating Gradients', color='#e74c3c', fontweight='bold')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(True, alpha=0.2, color='white')\n",
    "\n",
    "    # Plot 3: Code comparison\n",
    "    ax = axes[2]\n",
    "    ax.set_facecolor('#161b22')\n",
    "    ax.axis('off')\n",
    "\n",
    "    code_text = \"\"\"\n",
    "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    â•‘  WHY zero_grad() IS ESSENTIAL          â•‘\n",
    "    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "    â•‘                                        â•‘\n",
    "    â•‘  PyTorch ACCUMULATES gradients:        â•‘\n",
    "    â•‘                                        â•‘\n",
    "    â•‘    loss.backward()  # grad = g1        â•‘\n",
    "    â•‘    loss.backward()  # grad = g1 + g2   â•‘\n",
    "    â•‘    loss.backward()  # grad = g1+g2+g3  â•‘\n",
    "    â•‘                                        â•‘\n",
    "    â•‘  This causes EXPLOSION! âŒ              â•‘\n",
    "    â•‘                                        â•‘\n",
    "    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "    â•‘  CORRECT PATTERN:                      â•‘\n",
    "    â•‘                                        â•‘\n",
    "    â•‘    optimizer.zero_grad()  # Reset!     â•‘\n",
    "    â•‘    loss = compute_loss()               â•‘\n",
    "    â•‘    loss.backward()        # Fresh grad â•‘\n",
    "    â•‘    optimizer.step()       # Update     â•‘\n",
    "    â•‘                                        â•‘\n",
    "    â•‘  This converges properly! âœ…            â•‘\n",
    "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    \"\"\"\n",
    "    ax.text(0.05, 0.95, code_text, transform=ax.transAxes, fontsize=10,\n",
    "           fontfamily='monospace', color='#00ff88', verticalalignment='top')\n",
    "\n",
    "    plt.suptitle('âš ï¸ THE GRADIENT ACCUMULATION TRAP',\n",
    "                color='#ffd93d', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ============================================================\n",
    "# QUIZ COMPONENT\n",
    "# ============================================================\n",
    "\n",
    "quiz_questions = [\n",
    "    {\n",
    "        \"q\": \"What does a perceptron compute before applying the activation function?\",\n",
    "        \"options\": [\"The square of inputs\", \"A weighted sum plus bias\", \"The derivative\", \"Random noise\"],\n",
    "        \"answer\": 1,\n",
    "        \"explanation\": \"A perceptron computes z = wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚™xâ‚™ + b, which is a weighted sum of inputs plus a bias term.\"\n",
    "    },\n",
    "    {\n",
    "        \"q\": \"What's the key difference between step and sigmoid activation?\",\n",
    "        \"options\": [\n",
    "            \"Step is faster to compute\",\n",
    "            \"Step outputs 0 or 1 sharply; sigmoid outputs smooth values between 0-1\",\n",
    "            \"Sigmoid can only output negative numbers\",\n",
    "            \"They are exactly the same\"\n",
    "        ],\n",
    "        \"answer\": 1,\n",
    "        \"explanation\": \"Step function has a hard threshold (outputs exactly 0 or 1), while sigmoid provides a smooth, differentiable transition. This smoothness is crucial for gradient-based learning!\"\n",
    "    },\n",
    "    {\n",
    "        \"q\": \"Why can't a single perceptron solve the XOR problem?\",\n",
    "        \"options\": [\n",
    "            \"XOR is too complex mathematically\",\n",
    "            \"A single perceptron can only create linear decision boundaries\",\n",
    "            \"Perceptrons don't work with binary inputs\",\n",
    "            \"XOR requires at least 10 neurons\"\n",
    "        ],\n",
    "        \"answer\": 1,\n",
    "        \"explanation\": \"A single perceptron creates a linear decision boundary (a straight line in 2D). XOR requires a non-linear boundary - you can't draw a single straight line to separate XOR's classes!\"\n",
    "    },\n",
    "    {\n",
    "        \"q\": \"What role does the bias term play?\",\n",
    "        \"options\": [\n",
    "            \"It makes the network biased toward certain predictions\",\n",
    "            \"It shifts the decision boundary, allowing it to not pass through origin\",\n",
    "            \"It's only used during training\",\n",
    "            \"It controls the learning rate\"\n",
    "        ],\n",
    "        \"answer\": 1,\n",
    "        \"explanation\": \"The bias shifts the decision boundary. Without it, all decision boundaries would have to pass through the origin (0,0). The bias gives the perceptron flexibility in where to place the boundary.\"\n",
    "    },\n",
    "    {\n",
    "        \"q\": \"How does a perceptron 'learn' the correct weights?\",\n",
    "        \"options\": [\n",
    "            \"Weights are randomly assigned and never change\",\n",
    "            \"By adjusting weights to reduce prediction errors (gradient descent)\",\n",
    "            \"By copying weights from other perceptrons\",\n",
    "            \"Weights are manually set by programmers\"\n",
    "        ],\n",
    "        \"answer\": 1,\n",
    "        \"explanation\": \"Perceptrons learn through gradient descent: they compute the error between predictions and true values, then adjust weights in the direction that reduces this error. This is the foundation of neural network training!\"\n",
    "    }\n",
    "]\n",
    "\n",
    "current_quiz_idx = [0]\n",
    "\n",
    "def get_quiz_question():\n",
    "    q = quiz_questions[current_quiz_idx[0]]\n",
    "    options_text = \"\\n\".join([f\"{i+1}. {opt}\" for i, opt in enumerate(q[\"options\"])])\n",
    "    return f\"**Question {current_quiz_idx[0]+1}/{len(quiz_questions)}:**\\n\\n{q['q']}\\n\\n{options_text}\"\n",
    "\n",
    "def check_answer(answer_num):\n",
    "    if not answer_num:\n",
    "        return \"Please select an answer (1-4)\"\n",
    "    try:\n",
    "        ans = int(answer_num) - 1\n",
    "    except:\n",
    "        return \"Please enter a number 1-4\"\n",
    "\n",
    "    q = quiz_questions[current_quiz_idx[0]]\n",
    "    if ans == q[\"answer\"]:\n",
    "        result = f\"âœ… **Correct!**\\n\\n{q['explanation']}\"\n",
    "    else:\n",
    "        result = f\"âŒ **Not quite.** The correct answer is: {q['options'][q['answer']]}\\n\\n{q['explanation']}\"\n",
    "    return result\n",
    "\n",
    "def next_question():\n",
    "    current_quiz_idx[0] = (current_quiz_idx[0] + 1) % len(quiz_questions)\n",
    "    return get_quiz_question(), \"\"\n",
    "\n",
    "# ============================================================\n",
    "# BUILD THE INTERFACE\n",
    "# ============================================================\n",
    "\n",
    "with gr.Blocks(title=\"Perceptron Learning Lab\", theme=gr.themes.Soft()) as demo:\n",
    "\n",
    "    gr.Markdown(\"\"\"\n",
    "    # âš”ï¸ Perceptron Learning Lab: Star Wars Edition âš”ï¸\n",
    "\n",
    "    *\"Do or do not. There is no try... but there IS forward propagation!\"* - Yoda, probably\n",
    "\n",
    "    Learn how neural networks make decisions, one perceptron at a time!\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Tabs():\n",
    "\n",
    "        # -------- TAB 1: Forward Propagation --------\n",
    "        with gr.TabItem(\"1ï¸âƒ£ Forward Propagation\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### How Information Flows Through a Perceptron\n",
    "\n",
    "            A perceptron takes inputs, multiplies them by weights, adds a bias,\n",
    "            and passes the result through an activation function:\n",
    "\n",
    "            **z = wâ‚Â·xâ‚ + wâ‚‚Â·xâ‚‚ + b** â†’ **a = activation(z)**\n",
    "\n",
    "            Adjust the sliders to see how changing inputs and weights affects the output!\n",
    "            \"\"\")\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    x1_slider = gr.Slider(-5, 5, value=2, step=0.1, label=\"xâ‚ (Input 1)\")\n",
    "                    x2_slider = gr.Slider(-5, 5, value=3, step=0.1, label=\"xâ‚‚ (Input 2)\")\n",
    "                    w1_slider = gr.Slider(-3, 3, value=0.5, step=0.1, label=\"wâ‚ (Weight 1)\")\n",
    "                    w2_slider = gr.Slider(-3, 3, value=-0.8, step=0.1, label=\"wâ‚‚ (Weight 2)\")\n",
    "                    bias_slider = gr.Slider(-5, 5, value=1, step=0.1, label=\"b (Bias)\")\n",
    "                    activation_dropdown = gr.Dropdown(\n",
    "                        choices=['step', 'sigmoid', 'tanh', 'relu', 'linear'],\n",
    "                        value='sigmoid',\n",
    "                        label=\"Activation Function\"\n",
    "                    )\n",
    "\n",
    "                with gr.Column(scale=3):\n",
    "                    forward_plot = gr.Plot(label=\"Forward Propagation Visualization\")\n",
    "\n",
    "            forward_btn = gr.Button(\"ðŸš€ Visualize Forward Pass\", variant=\"primary\")\n",
    "            forward_btn.click(\n",
    "                visualize_forward_propagation,\n",
    "                [x1_slider, x2_slider, w1_slider, w2_slider, bias_slider, activation_dropdown],\n",
    "                forward_plot\n",
    "            )\n",
    "\n",
    "        # -------- TAB 2: Activation Functions --------\n",
    "        with gr.TabItem(\"2ï¸âƒ£ Activation Functions\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Compare Activation Functions\n",
    "\n",
    "            The activation function determines *how* the weighted sum is transformed into an output:\n",
    "\n",
    "            | Function | Output Range | Key Property |\n",
    "            |----------|--------------|--------------|\n",
    "            | **Step** | {0, 1} | Hard threshold, not differentiable |\n",
    "            | **Sigmoid** | (0, 1) | Smooth probability-like output |\n",
    "            | **Tanh** | (-1, 1) | Zero-centered, stronger gradients |\n",
    "            | **ReLU** | [0, âˆž) | Fast computation, sparse activation |\n",
    "            | **Linear** | (-âˆž, âˆž) | No transformation (baseline) |\n",
    "            \"\"\")\n",
    "\n",
    "            z_slider = gr.Slider(-5, 5, value=1.5, step=0.1,\n",
    "                               label=\"z (Weighted Sum) - Move to see different activations\")\n",
    "            activation_compare_plot = gr.Plot(label=\"Activation Function Comparison\")\n",
    "\n",
    "            compare_btn = gr.Button(\"ðŸ“Š Compare All Activations\", variant=\"primary\")\n",
    "            compare_btn.click(compare_activations, z_slider, activation_compare_plot)\n",
    "\n",
    "        # -------- TAB 3: Star Wars Prediction --------\n",
    "        with gr.TabItem(\"3ï¸âƒ£ Kylo's Destiny\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### ðŸŒŸ Will Kylo Ren Return to the Light Side?\n",
    "\n",
    "            Our perceptron predicts Kylo's fate based on:\n",
    "            - **xâ‚**: Number of meaningful encounters with Rey â¤ï¸\n",
    "            - **xâ‚‚**: Number of meaningful encounters with Luke ðŸ‘´\n",
    "\n",
    "            *More positive encounters = greater pull toward the light!*\n",
    "\n",
    "            Adjust the weights to represent how influential each person is:\n",
    "            \"\"\")\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    rey_slider = gr.Slider(0, 10, value=5, step=1, label=\"Encounters with Rey ðŸ‘§\")\n",
    "                    luke_slider = gr.Slider(0, 10, value=3, step=1, label=\"Encounters with Luke ðŸ§”\")\n",
    "                    w_rey_slider = gr.Slider(-2, 2, value=0.8, step=0.1, label=\"Rey's Influence (wâ‚)\")\n",
    "                    w_luke_slider = gr.Slider(-2, 2, value=0.5, step=0.1, label=\"Luke's Influence (wâ‚‚)\")\n",
    "                    kylo_bias_slider = gr.Slider(-10, 5, value=-4, step=0.5,\n",
    "                                                label=\"Dark Side Pull (bias) - negative = harder to turn\")\n",
    "                    kylo_activation = gr.Dropdown(\n",
    "                        choices=['sigmoid', 'tanh', 'step'],\n",
    "                        value='sigmoid',\n",
    "                        label=\"Activation (how sharply to decide)\"\n",
    "                    )\n",
    "\n",
    "                with gr.Column(scale=2):\n",
    "                    kylo_plot = gr.Plot(label=\"Kylo's Destiny Prediction\")\n",
    "\n",
    "            predict_btn = gr.Button(\"âš”ï¸ Predict Kylo's Fate!\", variant=\"primary\")\n",
    "            predict_btn.click(\n",
    "                kylo_prediction_interactive,\n",
    "                [rey_slider, luke_slider, w_rey_slider, w_luke_slider, kylo_bias_slider, kylo_activation],\n",
    "                kylo_plot\n",
    "            )\n",
    "\n",
    "        # -------- TAB 4: Decision Boundary --------\n",
    "        with gr.TabItem(\"4ï¸âƒ£ Decision Boundary\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### The Separating Line\n",
    "\n",
    "            A perceptron creates a **linear decision boundary** - a straight line that\n",
    "            divides the input space into two regions.\n",
    "\n",
    "            The equation **wâ‚Â·xâ‚ + wâ‚‚Â·xâ‚‚ + b = 0** defines this line!\n",
    "\n",
    "            - Points above/right: Predicted class 1 (Light Side)\n",
    "            - Points below/left: Predicted class 0 (Dark Side)\n",
    "            \"\"\")\n",
    "\n",
    "            with gr.Row():\n",
    "                db_w1 = gr.Slider(-2, 2, value=0.8, step=0.1, label=\"wâ‚ (Rey coefficient)\")\n",
    "                db_w2 = gr.Slider(-2, 2, value=0.5, step=0.1, label=\"wâ‚‚ (Luke coefficient)\")\n",
    "                db_bias = gr.Slider(-10, 10, value=-4, step=0.5, label=\"Bias (shifts the line)\")\n",
    "                db_activation = gr.Dropdown(\n",
    "                    choices=['step', 'sigmoid', 'tanh'],\n",
    "                    value='sigmoid',\n",
    "                    label=\"Activation Function\"\n",
    "                )\n",
    "\n",
    "            boundary_plot = gr.Plot(label=\"Decision Boundary Visualization\")\n",
    "            boundary_btn = gr.Button(\"ðŸ“ˆ Show Decision Boundary\", variant=\"primary\")\n",
    "            boundary_btn.click(\n",
    "                visualize_decision_boundary,\n",
    "                [db_w1, db_w2, db_bias, db_activation],\n",
    "                boundary_plot\n",
    "            )\n",
    "\n",
    "        # -------- TAB 5: Perceptron vs Regression --------\n",
    "        with gr.TabItem(\"5ï¸âƒ£ vs Linear Regression\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Perceptron vs Linear Regression\n",
    "\n",
    "            Both find a line, but for different purposes:\n",
    "\n",
    "            | | Linear Regression | Perceptron |\n",
    "            |---|---|---|\n",
    "            | **Goal** | Predict continuous value | Classify into categories |\n",
    "            | **Output** | Any real number | 0/1 or probability |\n",
    "            | **Loss** | Mean squared error | Cross-entropy/perceptron loss |\n",
    "            | **Best for** | \"How much?\" questions | \"Which class?\" questions |\n",
    "            \"\"\")\n",
    "\n",
    "            with gr.Row():\n",
    "                reg_slope = gr.Slider(-2, 2, value=1, step=0.1, label=\"Decision boundary slope\")\n",
    "                reg_intercept = gr.Slider(-5, 10, value=4, step=0.5, label=\"Decision boundary intercept\")\n",
    "                reg_threshold = gr.Slider(0, 1, value=0.5, step=0.1, label=\"Classification threshold\")\n",
    "\n",
    "            regression_plot = gr.Plot(label=\"Comparison\")\n",
    "            regression_btn = gr.Button(\"ðŸ”¬ Compare Methods\", variant=\"primary\")\n",
    "            regression_btn.click(\n",
    "                perceptron_vs_regression,\n",
    "                [reg_slope, reg_intercept, reg_threshold],\n",
    "                regression_plot\n",
    "            )\n",
    "\n",
    "        # -------- TAB 6: Training --------\n",
    "        with gr.TabItem(\"6ï¸âƒ£ Training\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### How Does a Perceptron Learn?\n",
    "\n",
    "            Training uses **gradient descent**:\n",
    "            1. Make a prediction\n",
    "            2. Calculate the error (loss)\n",
    "            3. Adjust weights to reduce error\n",
    "            4. Repeat!\n",
    "\n",
    "            The **learning rate** controls how big each adjustment is.\n",
    "            \"\"\")\n",
    "\n",
    "            with gr.Row():\n",
    "                lr_slider = gr.Slider(0.01, 1.0, value=0.1, step=0.01, label=\"Learning Rate\")\n",
    "                epochs_slider = gr.Slider(10, 200, value=50, step=10, label=\"Number of Epochs\")\n",
    "\n",
    "            training_plot = gr.Plot(label=\"Training Visualization\")\n",
    "            train_btn = gr.Button(\"ðŸŽ“ Train the Perceptron!\", variant=\"primary\")\n",
    "            train_btn.click(\n",
    "                train_perceptron_visualization,\n",
    "                [lr_slider, epochs_slider],\n",
    "                training_plot\n",
    "            )\n",
    "\n",
    "        # -------- TAB 7: Limitations (XOR) --------\n",
    "        with gr.TabItem(\"7ï¸âƒ£ Limitations\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### The XOR Problem: A Single Perceptron's Kryptonite\n",
    "\n",
    "            The XOR (exclusive or) function:\n",
    "            - (0,0) â†’ 0, (1,1) â†’ 0 (both same â†’ 0)\n",
    "            - (0,1) â†’ 1, (1,0) â†’ 1 (different â†’ 1)\n",
    "\n",
    "            **Try drawing a single straight line to separate the 1s from 0s... you can't!**\n",
    "\n",
    "            This is why we need **multi-layer neural networks** for complex problems.\n",
    "            \"\"\")\n",
    "\n",
    "            xor_plot = gr.Plot(label=\"XOR Problem Visualization\")\n",
    "            xor_btn = gr.Button(\"ðŸ§© Show XOR Problem\", variant=\"primary\")\n",
    "            xor_btn.click(show_nonlinearity_limitation, outputs=xor_plot)\n",
    "\n",
    "        # -------- TAB 8: Decision Boundary Gallery --------\n",
    "        with gr.TabItem(\"8ï¸âƒ£ Boundary Zoo\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### ðŸŽ¯ Decision Boundary Gallery: Match Model to Data!\n",
    "\n",
    "            Different models create **different shaped decision boundaries**.\n",
    "            The key insight: **match your model's complexity to your data's complexity!**\n",
    "\n",
    "            | Data Pattern | Best Model | Boundary Shape |\n",
    "            |--------------|------------|----------------|\n",
    "            | Two separate blobs | Perceptron | Straight line |\n",
    "            | Inner vs outer ring | RBF SVM | Circle |\n",
    "            | Curved separation | Polynomial | Parabola |\n",
    "            | Checkerboard/XOR | Neural Network | Multiple regions |\n",
    "            | Interleaved spirals | Deep Network | Complex curves |\n",
    "            | Categorical splits | Decision Tree | Rectangles |\n",
    "\n",
    "            **Explore each type below:**\n",
    "            \"\"\")\n",
    "\n",
    "            boundary_dropdown = gr.Dropdown(\n",
    "                choices=[\n",
    "                    \"Linear (Perceptron)\",\n",
    "                    \"Circular (Radial)\",\n",
    "                    \"Quadratic (Polynomial)\",\n",
    "                    \"XOR (Multi-region)\",\n",
    "                    \"Spiral (Highly Nonlinear)\",\n",
    "                    \"Rectangular (Decision Tree)\"\n",
    "                ],\n",
    "                value=\"Linear (Perceptron)\",\n",
    "                label=\"Select Boundary Type\"\n",
    "            )\n",
    "\n",
    "            boundary_plot = gr.Plot(label=\"Decision Boundary Visualization\")\n",
    "            boundary_btn = gr.Button(\"ðŸ”® Show Boundary & Ideal Data\", variant=\"primary\")\n",
    "            boundary_btn.click(visualize_boundary_gallery, boundary_dropdown, boundary_plot)\n",
    "\n",
    "            gr.Markdown(\"### Compare All Boundaries at Once\")\n",
    "            all_boundaries_plot = gr.Plot(label=\"All Boundary Types\")\n",
    "            all_btn = gr.Button(\"ðŸ“Š Show All 6 Boundary Types\", variant=\"secondary\")\n",
    "            all_btn.click(compare_all_boundaries, outputs=all_boundaries_plot)\n",
    "\n",
    "            gr.Markdown(\"\"\"\n",
    "            ---\n",
    "            ### ðŸ’¡ Key Takeaways\n",
    "\n",
    "            1. **Linear models** (perceptron, logistic regression) can only draw straight lines\n",
    "            2. **Adding polynomial features** (xÂ², xâ‚xâ‚‚) lets linear models learn curves\n",
    "            3. **Kernel tricks** (RBF, polynomial kernels) implicitly map to higher dimensions\n",
    "            4. **Neural networks** with hidden layers can learn *any* boundary shape\n",
    "            5. **Decision trees** make axis-aligned splits (good for categorical data)\n",
    "            6. **More complex â‰  better!** Overly complex models overfit to noise\n",
    "            \"\"\")\n",
    "\n",
    "        # -------- TAB 9: Gradient Descent Education --------\n",
    "        with gr.TabItem(\"9ï¸âƒ£ Gradients 101\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### ðŸŽ“ Understanding Gradient Descent: Manual vs Autograd\n",
    "\n",
    "            This is **the most important concept** in deep learning! Let's break it down:\n",
    "\n",
    "            | Step | What Happens | Code |\n",
    "            |------|--------------|------|\n",
    "            | **Forward Pass** | Compute prediction & loss | `y_pred = w*x + b; loss = (y_pred - y)Â²` |\n",
    "            | **Backward Pass** | Compute gradients via chain rule | `loss.backward()` |\n",
    "            | **Update** | Adjust weights to reduce loss | `w = w - lr * grad` |\n",
    "\n",
    "            **The Chain Rule** is how we compute gradients:\n",
    "            ```\n",
    "            âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚Å· Ã— âˆ‚Å·/âˆ‚w\n",
    "            ```\n",
    "\n",
    "            Let's see this in action with a simple example: fitting `w*x + b` to a target value.\n",
    "            \"\"\")\n",
    "\n",
    "            gr.Markdown(\"### Step-by-Step Gradient Computation\")\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    grad_x = gr.Slider(0.5, 5, value=2, step=0.5, label=\"Input x\")\n",
    "                    grad_target = gr.Slider(1, 20, value=10, step=1, label=\"Target y\")\n",
    "                    grad_w = gr.Slider(-2, 5, value=1, step=0.1, label=\"Initial weight w\")\n",
    "                    grad_b = gr.Slider(-5, 5, value=0, step=0.1, label=\"Initial bias b\")\n",
    "                    grad_lr = gr.Slider(0.001, 0.5, value=0.01, step=0.001, label=\"Learning rate\")\n",
    "\n",
    "                with gr.Column(scale=3):\n",
    "                    gradient_plot = gr.Plot(label=\"Gradient Computation Visualization\")\n",
    "\n",
    "            gradient_btn = gr.Button(\"ðŸ”¬ Show Forward + Backward Pass\", variant=\"primary\")\n",
    "            gradient_btn.click(\n",
    "                visualize_gradient_computation,\n",
    "                [grad_x, grad_target, grad_w, grad_b, grad_lr],\n",
    "                gradient_plot\n",
    "            )\n",
    "\n",
    "            gr.Markdown(\"### Watch Training Converge Over Multiple Steps\")\n",
    "\n",
    "            with gr.Row():\n",
    "                train_x = gr.Slider(0.5, 5, value=2, step=0.5, label=\"Input x\")\n",
    "                train_target = gr.Slider(1, 20, value=10, step=1, label=\"Target y\")\n",
    "                train_w = gr.Slider(-2, 5, value=1, step=0.1, label=\"Initial w\")\n",
    "                train_b = gr.Slider(-5, 5, value=0, step=0.1, label=\"Initial b\")\n",
    "                train_lr = gr.Slider(0.001, 0.5, value=0.05, step=0.001, label=\"Learning rate\")\n",
    "                train_steps = gr.Slider(5, 100, value=30, step=5, label=\"Number of steps\")\n",
    "\n",
    "            training_conv_plot = gr.Plot(label=\"Training Convergence\")\n",
    "            train_conv_btn = gr.Button(\"ðŸ“ˆ Run Training Loop\", variant=\"primary\")\n",
    "            train_conv_btn.click(\n",
    "                visualize_training_steps,\n",
    "                [train_x, train_target, train_w, train_b, train_lr, train_steps],\n",
    "                training_conv_plot\n",
    "            )\n",
    "\n",
    "            gr.Markdown(\"### âš ï¸ Why `optimizer.zero_grad()` Matters\")\n",
    "\n",
    "            zero_grad_plot = gr.Plot(label=\"Gradient Accumulation Problem\")\n",
    "            zero_grad_btn = gr.Button(\"ðŸš¨ Show Gradient Accumulation Trap\", variant=\"secondary\")\n",
    "            zero_grad_btn.click(show_gradient_accumulation_problem, outputs=zero_grad_plot)\n",
    "\n",
    "            gr.Markdown(\"\"\"\n",
    "            ---\n",
    "            ### ðŸ“ PyTorch Code Pattern\n",
    "\n",
    "            ```python\n",
    "            # Initialize\n",
    "            w = torch.tensor(1.0, requires_grad=True)\n",
    "            b = torch.tensor(0.0, requires_grad=True)\n",
    "            optimizer = torch.optim.SGD([w, b], lr=0.01)\n",
    "\n",
    "            # Training loop\n",
    "            for epoch in range(100):\n",
    "                # Forward pass\n",
    "                y_pred = w * x + b\n",
    "                loss = (y_pred - target) ** 2\n",
    "\n",
    "                # Backward pass (autograd computes gradients!)\n",
    "                loss.backward()\n",
    "\n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "\n",
    "                # CRITICAL: Reset gradients for next iteration!\n",
    "                optimizer.zero_grad()\n",
    "            ```\n",
    "\n",
    "            **Autograd does the calculus for you!** No manual derivatives needed.\n",
    "            \"\"\")\n",
    "\n",
    "        # -------- TAB 10: Quiz --------\n",
    "        with gr.TabItem(\"ðŸ”Ÿ Knowledge Check\"):\n",
    "            gr.Markdown(\"### Test Your Understanding!\")\n",
    "\n",
    "            quiz_display = gr.Markdown(get_quiz_question())\n",
    "            answer_input = gr.Textbox(label=\"Your Answer (1-4)\", placeholder=\"Enter 1, 2, 3, or 4\")\n",
    "\n",
    "            with gr.Row():\n",
    "                check_btn = gr.Button(\"Check Answer\", variant=\"primary\")\n",
    "                next_btn = gr.Button(\"Next Question\")\n",
    "\n",
    "            result_display = gr.Markdown(\"\")\n",
    "\n",
    "            check_btn.click(check_answer, answer_input, result_display)\n",
    "            next_btn.click(next_question, outputs=[quiz_display, result_display])\n",
    "\n",
    "        # -------- TAB 11: Architecture Reference --------\n",
    "        with gr.TabItem(\"ðŸ“ Reference\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Perceptron Architecture\n",
    "\n",
    "            ```\n",
    "            INPUTS           WEIGHTS        SUMMATION      ACTIVATION       OUTPUT\n",
    "            â•â•â•â•â•â•â•          â•â•â•â•â•â•â•        â•â•â•â•â•â•â•â•â•      â•â•â•â•â•â•â•â•â•â•       â•â•â•â•â•â•\n",
    "\n",
    "              xâ‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ wâ‚ â”€â”€â”€â”\n",
    "                                    â”œâ”€â”€â†’ Î£ (z = Î£wáµ¢xáµ¢ + b) â”€â”€â†’ f(z) â”€â”€â†’ Å·\n",
    "              xâ‚‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ wâ‚‚ â”€â”€â”€â”˜         â†‘\n",
    "                                              â”‚\n",
    "              +1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ b â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "            (bias)\n",
    "            ```\n",
    "\n",
    "            ### Key Equations\n",
    "\n",
    "            | Component | Equation | Description |\n",
    "            |-----------|----------|-------------|\n",
    "            | Weighted Sum | z = Î£ wáµ¢xáµ¢ + b | Linear combination of inputs |\n",
    "            | Step Activation | f(z) = 1 if zâ‰¥0 else 0 | Hard binary decision |\n",
    "            | Sigmoid Activation | f(z) = 1/(1+eâ»á¶») | Smooth probability output |\n",
    "            | Perceptron Update | wáµ¢ â† wáµ¢ + Î·(y-Å·)xáµ¢ | Learning rule |\n",
    "\n",
    "            ### The Decision Boundary\n",
    "\n",
    "            For 2D inputs, the equation **wâ‚xâ‚ + wâ‚‚xâ‚‚ + b = 0** defines a line:\n",
    "\n",
    "            - Rearranged: **xâ‚‚ = -(wâ‚/wâ‚‚)xâ‚ - (b/wâ‚‚)**\n",
    "            - Slope: **-wâ‚/wâ‚‚**\n",
    "            - Intercept: **-b/wâ‚‚**\n",
    "\n",
    "            ### Historical Note\n",
    "\n",
    "            The perceptron was invented by Frank Rosenblatt in 1958. Minsky & Papert's 1969 book\n",
    "            showed its limitations (XOR problem), temporarily halting neural network research.\n",
    "            The solution: **multi-layer perceptrons** (MLPs) with hidden layers!\n",
    "            \"\"\")\n",
    "\n",
    "            # Show pixel art characters\n",
    "            gr.Markdown(\"### Our Star Wars Cast\")\n",
    "\n",
    "            with gr.Row():\n",
    "                char_plot = gr.Plot()\n",
    "\n",
    "            def show_characters():\n",
    "                fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "                fig.patch.set_facecolor('#0d1117')\n",
    "\n",
    "                chars = [\n",
    "                    (create_own_char(), 'Perry the Platypus\\n\"Wheres Perry\"'),\n",
    "                    (create_rey(), 'Rey\\n\"The Force is strong\\nwith gradients\"'),\n",
    "                    (create_luke(), 'Luke\\n\"I sense the bias\\nin you\"'),\n",
    "                    (create_kylo(), 'Kylo Ren\\n\"I will finish what\\nthe perceptron started\"')\n",
    "                ]\n",
    "\n",
    "                for ax, (img, title) in zip(axes, chars):\n",
    "                    ax.imshow(img, interpolation='nearest')\n",
    "                    ax.set_title(title, color='white', fontsize=9)\n",
    "                    ax.axis('off')\n",
    "                    ax.set_facecolor('#0d1117')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                return fig\n",
    "\n",
    "            char_btn = gr.Button(\"ðŸ‘¾ Show Pixel Art Characters\")\n",
    "            char_btn.click(show_characters, outputs=char_plot)\n",
    "\n",
    "    gr.Markdown(\"\"\"\n",
    "    ---\n",
    "    ### ðŸ“š Further Learning\n",
    "    - [3Blue1Brown: Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n",
    "    - [The Perceptron Paper (Rosenblatt, 1958)](https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1958.pdf)\n",
    "    - [Neural Networks and Deep Learning (Free Online Book)](http://neuralnetworksanddeeplearning.com/)\n",
    "\n",
    "    *May the gradients be with you!* âš”ï¸\n",
    "    \"\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPTqrrqvf4n39cuL0Rc68pQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hw_mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
